{"config":{"lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"index.html","text":"Welcome to MkDocs \u00b6 For full documentation visit mkdocs.org . Commands \u00b6 mkdocs new [dir-name] - Create a new project. mkdocs serve - Start the live-reloading docs server. mkdocs build - Build the documentation site. mkdocs help - Print this help message. Project layout \u00b6 mkdocs.yml # The configuration file. docs/ index.md # The documentation homepage. ... # Other markdown pages, images and other files.","title":"Home"},{"location":"index.html#welcome-to-mkdocs","text":"For full documentation visit mkdocs.org .","title":"Welcome to MkDocs"},{"location":"index.html#commands","text":"mkdocs new [dir-name] - Create a new project. mkdocs serve - Start the live-reloading docs server. mkdocs build - Build the documentation site. mkdocs help - Print this help message.","title":"Commands"},{"location":"index.html#project-layout","text":"mkdocs.yml # The configuration file. docs/ index.md # The documentation homepage. ... # Other markdown pages, images and other files.","title":"Project layout"},{"location":"license.html","text":"MkDocs License (BSD) \u00b6 Copyright \u00a9 2014, Tom Christie. All rights reserved. Redistribution and use in source and binary forms, with or without modification, are permitted provided that the following conditions are met: Redistributions of source code must retain the above copyright notice, this list of conditions and the following disclaimer. Redistributions in binary form must reproduce the above copyright notice, this list of conditions and the following disclaimer in the documentation and/or other materials provided with the distribution. THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS \"AS IS\" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE. Theme: Material for MkDocs \u00b6 MIT License Copyright \u00a9 2016 - 2017 Martin Donath Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \"Software\"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions: The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software. THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NON-INFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.","title":"License"},{"location":"license.html#mkdocs-license-bsd","text":"Copyright \u00a9 2014, Tom Christie. All rights reserved. Redistribution and use in source and binary forms, with or without modification, are permitted provided that the following conditions are met: Redistributions of source code must retain the above copyright notice, this list of conditions and the following disclaimer. Redistributions in binary form must reproduce the above copyright notice, this list of conditions and the following disclaimer in the documentation and/or other materials provided with the distribution. THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS \"AS IS\" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.","title":"MkDocs License (BSD)"},{"location":"license.html#theme-material-for-mkdocs","text":"MIT License Copyright \u00a9 2016 - 2017 Martin Donath Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \"Software\"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions: The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software. THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NON-INFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.","title":"Theme: Material for MkDocs"},{"location":"dask/dask.html","text":"Dask Working Notes \u00b6 Rotate Long Column Wide - Multiple \u00b6 import pandas as pd import dask.dataframe as dd import numpy as np def convert_dates_to_strings ( df , date_columns : list , date_format ) -> dd . DataFrame : for col in date_columns : df [ col ] = df [ col ] . dt . strftime ( date_format ) df [ col ] = df [ col ] . replace ( \"01011800\" , \"\" ) return df df = pd . DataFrame ( { \"bene_id\" : [ \"1\" , \"1\" , \"1\" , \"1\" , \"1\" ], \"hdr_icn\" : [ \"1\" , \"1\" , \"2\" , \"2\" , \"2\" ], \"rot1\" : [ \"A\" , \"B\" , \"C\" , \" \" , \"E\" ], \"rot2\" : [ \"X\" , \"Y\" , \"Z\" , \" \" , \" \" ], \"rot3\" : [ pd . to_datetime ( \"2018-01-01\" ), pd . to_datetime ( \"2018-01-01\" ), pd . to_datetime ( \"2018-01-01\" ), pd . to_datetime ( \"2018-01-01\" ), pd . to_datetime ( \"2018-01-01\" ), ], } ) ddf = dd . from_pandas ( df , 4 ) ddf = convert_dates_to_strings ( ddf , [ \"rot3\" ], \"%m %d %Y\" ) ddf = ddf . set_index ( \"bene_id\" ) . persist () def agg_func ( x ): return pd . Series ( dict ( # 14.7 ms \u00b1 287 \u00b5s per loop (mean \u00b1 std. dev. of 7 runs, 100 loops each) # rot1=\"%s\" % \";\".join(x[\"rot1\"]), # rot2=\"%s\" % \";\".join(x[\"rot2\"]), # rot3=\"%s\" % \";\".join(x[\"rot3\"]), # 14.7 ms \u00b1 493 \u00b5s per loop (mean \u00b1 std. dev. of 7 runs, 100 loops each) # rot1=f'{\";\".join(x[\"rot1\"])}', # rot2=f'{\";\".join(x[\"rot2\"])}', # rot3=f'{\";\".join(x[\"rot3\"])}', # 14.8 ms \u00b1 314 \u00b5s per loop (mean \u00b1 std. dev. of 7 runs, 100 loops each) rot1 = \";\" . join ( x [ \"rot1\" ]), rot2 = \";\" . join ( x [ \"rot2\" ]), rot3 = \";\" . join ( x [ \"rot3\" ]), ) ) ddf . groupby ([ \"bene_id\" , \"hdr_icn\" ]) . apply ( agg_func , meta = { \"rot1\" : \"str\" , \"rot2\" : \"str\" , \"rot3\" : \"str\" } ) . compute () We can condense some of this code down by passing a list of columns to agg_func. import pandas as pd import dask.dataframe as dd import numpy as np def convert_dates_to_strings ( df , date_columns : list , date_format ) -> dd . DataFrame : for col in date_columns : df [ col ] = df [ col ] . dt . strftime ( date_format ) df [ col ] = df [ col ] . replace ( \"01011800\" , \"\" ) return df df = pd . DataFrame ( { \"bene_id\" : [ \"1\" , \"1\" , \"1\" , \"1\" , \"1\" ], \"hdr_icn\" : [ \"1\" , \"1\" , \"2\" , \"2\" , \"2\" ], \"rot1\" : [ \"A\" , \"B\" , \"C\" , \" \" , \"E\" ], \"rot2\" : [ \"X\" , \"Y\" , \"Z\" , \" \" , \" \" ], \"rot3\" : [ pd . to_datetime ( \"2018-01-01\" ), pd . to_datetime ( \"2018-01-01\" ), pd . to_datetime ( \"2018-01-01\" ), pd . to_datetime ( \"2018-01-01\" ), pd . to_datetime ( \"2018-01-01\" ), ], } ) ddf = dd . from_pandas ( df , 4 ) ddf = convert_dates_to_strings ( ddf , [ \"rot3\" ], \"%m %d %Y\" ) ddf = ddf . set_index ( \"bene_id\" ) . persist () def agg_func ( x , cols ): return pd . Series ({ col : \";\" . join ( x [ col ]) for col in cols }) ddf . groupby ([ \"bene_id\" , \"hdr_icn\" ]) . apply ( agg_func , [ \"rot1\" , \"rot2\" , \"rot3\" ]) . compute () We can further reduce runtime by providing agg_func with the expected \"meta\" output from .apply(...) import pandas as pd import dask.dataframe as dd import numpy as np def convert_dates_to_strings ( df , date_columns : list , date_format ) -> dd . DataFrame : for col in date_columns : df [ col ] = df [ col ] . dt . strftime ( date_format ) df [ col ] = df [ col ] . replace ( \"01011800\" , \"\" ) return df df = pd . DataFrame ( { \"bene_id\" : [ \"1\" , \"1\" , \"1\" , \"1\" , \"1\" ], \"hdr_icn\" : [ \"1\" , \"1\" , \"2\" , \"2\" , \"2\" ], \"rot1\" : [ \"A\" , \"B\" , \"C\" , \" \" , \"E\" ], \"rot2\" : [ \"X\" , \"Y\" , \"Z\" , \" \" , \" \" ], \"rot3\" : [ pd . to_datetime ( \"2018-01-01\" ), pd . to_datetime ( \"2018-01-01\" ), pd . to_datetime ( \"2018-01-01\" ), pd . to_datetime ( \"2018-01-01\" ), pd . to_datetime ( \"2018-01-01\" ), ], } ) ddf = dd . from_pandas ( df , 4 ) ddf = convert_dates_to_strings ( ddf , [ \"rot3\" ], \"%m %d %Y\" ) ddf = ddf . set_index ( \"bene_id\" ) . persist () def agg_func ( x , cols ): return pd . Series ({ col : \";\" . join ( x [ col ]) for col in cols }) # On a subset of data, pass the groupby object to dask.dataframe.utils.make_meta() ddf_meta = dd . utils . make_meta ( ddf . groupby ([ \"bene_id\" , \"hdr_icn\" ]) . apply ( agg_func , [ \"rot1\" , \"rot2\" , \"rot3\" ])) # You can view what you'll need to use as the meta object by accessing ddf_meta & ddf_meta.index >> ddf_meta Empty DataFrame Columns : [ rot1 , rot2 , rot3 ] Index : [] >> ddf_meta . index MultiIndex ( levels = [[ 'a' , 'b' ], [ 'foo' ]], codes = [[], []], names = [ 'bene_id' , 'hdr_icn' ]) # The ddf_meta object obviously wont be available @ runtime - we use the output to manually define # the object's properties typed_ddf_meta = pd . DataFrame ( columns = [ \"rot1\" , \"rot2\" , \"rot3\" ], index = pd . MultiIndex ( levels = [[ \"a\" , \"b\" ], [ \"foo\" ]], codes = [[], []], names = [ \"bene_id\" , \"hdr_icn\" ] ), ) typed_ddf_meta = ddf_meta . astype ( dtype = { \"rot1\" : \"str\" , \"rot2\" : \"str\" , \"rot3\" : \"str\" }) # note that the output of typed_ddf_meta and ddf_meta are equivalent # you can now pass typed_ddf_meta as the meta object to .apply() - you should notice a marginal speedup ddf . groupby ([ \"bene_id\" , \"hdr_icn\" ]) . apply ( agg_func , [ \"rot1\" , \"rot2\" , \"rot3\" ], meta = typed_ddf_meta ) . compute () It wouldn't make sense to run the .groupby() @ runtime, every time, to generate the meta_ddf information, so we'll define it by hand below: import pandas as pd import dask.dataframe as dd import numpy as np def convert_dates_to_strings ( df , date_columns : list , date_format ) -> dd . DataFrame : for col in date_columns : df [ col ] = df [ col ] . dt . strftime ( date_format ) df [ col ] = df [ col ] . replace ( \"01011800\" , \"\" ) return df df = pd . DataFrame ( { \"bene_id\" : [ \"1\" , \"1\" , \"1\" , \"1\" , \"1\" ], \"hdr_icn\" : [ \"1\" , \"1\" , \"2\" , \"2\" , \"2\" ], \"rot1\" : [ \"A\" , \"B\" , \"C\" , \" \" , \"E\" ], \"rot2\" : [ \"X\" , \"Y\" , \"Z\" , \" \" , \" \" ], \"rot3\" : [ pd . to_datetime ( \"2018-01-01\" ), pd . to_datetime ( \"2018-01-01\" ), pd . to_datetime ( \"2018-01-01\" ), pd . to_datetime ( \"2018-01-01\" ), pd . to_datetime ( \"2018-01-01\" ), ], } ) ddf = dd . from_pandas ( df , 4 ) ddf = convert_dates_to_strings ( ddf , [ \"rot3\" ], \"%m %d %Y\" ) ddf = ddf . set_index ( \"bene_id\" ) . persist () def agg_func ( x , cols ): return pd . Series ({ col : \";\" . join ( x [ col ]) for col in cols }) # Create ddf_meta object representing expected output from .apply() ddf_meta = pd . DataFrame ( columns = [ \"rot1\" , \"rot2\" , \"rot3\" ], index = pd . MultiIndex ( levels = [[ \"a\" , \"b\" ], [ \"foo\" ]], codes = [[], []], names = [ \"bene_id\" , \"hdr_icn\" ] ), ) ddf_meta = ddf_meta . astype ( dtype = { \"rot1\" : \"str\" , \"rot2\" : \"str\" , \"rot3\" : \"str\" }) # Pass ddf_meta to .apply(..., meta=ddf_meta) ddf . groupby ([ \"bene_id\" , \"hdr_icn\" ]) . apply ( agg_func , [ \"rot1\" , \"rot2\" , \"rot3\" ], meta = ddf_meta ) . compute () Joining on Index + Separate Column \u00b6 Setup Data \u00b6 import pandas as pd import dask.dataframe as dd from io import StringIO ddf1_string = StringIO ( \"\"\"hdr_icn_num,ver,col1 1,1,foo 2,1,foo 3,1,foo 4,1,foo 5,1,foo \"\"\" ) ddf1 = dd . from_pandas ( pd . read_csv ( ddf1_string , sep = \",\" ), 5 ) ddf1 = ddf1 . set_index ( \"hdr_icn_num\" ) ddf2_string = StringIO ( \"\"\"hdr_icn_num,ver,col2,col3 1,1,bar!,baz 1,2,X,X 2,1,bar!, 2,2,X,X 3,1,bar!,baz 3,2,X,X 4,1,bar!, 4,2,X,X 5,1,bar!,baz 5,2,X,X \"\"\" ) ddf2 = dd . from_pandas ( pd . read_csv ( ddf2_string , sep = \",\" , keep_default_na = False ), 5 ) ddf2 = ddf2 . set_index ( \"hdr_icn_num\" ) ddf1 . head ( 10 , ddf1 . npartitions ) ddf2 . head ( 10 , ddf2 . npartitions ) Works \u00b6 join_df = dd . merge ( left = ddf1 , right = ddf2 , on = [ \"hdr_icn_num\" ], left_on = [ \"hdr_icn_num\" , \"ver\" ], right_on = [ \"hdr_icn_num\" , \"ver\" ], how = \"left\" , ) join_df . head ( 10 , join_df . npartitions ) Works \u00b6 join_df = dd . merge ( left = ddf1 , right = ddf2 , left_on = [ \"hdr_icn_num\" , \"ver\" ], right_on = [ \"hdr_icn_num\" , \"ver\" ], how = \"left\" , ) join_df . head ( 10 , join_df . npartitions ) Does Not Work \u00b6 join_df = dd . merge ( left = ddf1 , right = ddf2 , left_index = True , right_index = True , left_on = [ \"ver\" ], right_on = [ \"ver\" ], how = \"left\" , ) join_df . head ( 10 , join_df . npartitions ) Task / Scheduler Notes \u00b6 Run on Scheduler \u00b6 client.run_on_scheduler takes a custom function. The custom function should include an argument dask_scheduler if the custom function requires access to the Scheduler object and its API . client = Client ( \"etcetc\" ) # shows tasks on workers client . has_what () def get_task_stream ( dask_scheduler ): # Shows tasks that have been run/submitted in the past? return dask_scheduler . get_task_stream () def kill_task_across_clients ( dask_sheduler , task_key ): # Kill some task that exist w/some client # task_key == 'etc_etc-c07efb0ea6dd8c15df9a948ccd19e28c' for client in dask_scheduler . clients : dask_scheduler . cancel_key ( key = task_key , client = client ) task_stream = client . run_on_scheduler ( get_task_stream ) def user_info () -> dict : \"\"\" Returns dict of user information for the current process. Returns: Dict \"\"\" import os import getpass return dict ( uid = os . geteuid (), gid = os . getgid (), egid = os . getegid (), groups = os . getgroups (), user = getpass . getuser (), ) # Retrieve user info for the scheduler owner client . run_on_scheduler ( user_info ) user_info ()","title":"Dask"},{"location":"dask/dask.html#dask-working-notes","text":"","title":"Dask Working Notes"},{"location":"dask/dask.html#rotate-long-column-wide-multiple","text":"import pandas as pd import dask.dataframe as dd import numpy as np def convert_dates_to_strings ( df , date_columns : list , date_format ) -> dd . DataFrame : for col in date_columns : df [ col ] = df [ col ] . dt . strftime ( date_format ) df [ col ] = df [ col ] . replace ( \"01011800\" , \"\" ) return df df = pd . DataFrame ( { \"bene_id\" : [ \"1\" , \"1\" , \"1\" , \"1\" , \"1\" ], \"hdr_icn\" : [ \"1\" , \"1\" , \"2\" , \"2\" , \"2\" ], \"rot1\" : [ \"A\" , \"B\" , \"C\" , \" \" , \"E\" ], \"rot2\" : [ \"X\" , \"Y\" , \"Z\" , \" \" , \" \" ], \"rot3\" : [ pd . to_datetime ( \"2018-01-01\" ), pd . to_datetime ( \"2018-01-01\" ), pd . to_datetime ( \"2018-01-01\" ), pd . to_datetime ( \"2018-01-01\" ), pd . to_datetime ( \"2018-01-01\" ), ], } ) ddf = dd . from_pandas ( df , 4 ) ddf = convert_dates_to_strings ( ddf , [ \"rot3\" ], \"%m %d %Y\" ) ddf = ddf . set_index ( \"bene_id\" ) . persist () def agg_func ( x ): return pd . Series ( dict ( # 14.7 ms \u00b1 287 \u00b5s per loop (mean \u00b1 std. dev. of 7 runs, 100 loops each) # rot1=\"%s\" % \";\".join(x[\"rot1\"]), # rot2=\"%s\" % \";\".join(x[\"rot2\"]), # rot3=\"%s\" % \";\".join(x[\"rot3\"]), # 14.7 ms \u00b1 493 \u00b5s per loop (mean \u00b1 std. dev. of 7 runs, 100 loops each) # rot1=f'{\";\".join(x[\"rot1\"])}', # rot2=f'{\";\".join(x[\"rot2\"])}', # rot3=f'{\";\".join(x[\"rot3\"])}', # 14.8 ms \u00b1 314 \u00b5s per loop (mean \u00b1 std. dev. of 7 runs, 100 loops each) rot1 = \";\" . join ( x [ \"rot1\" ]), rot2 = \";\" . join ( x [ \"rot2\" ]), rot3 = \";\" . join ( x [ \"rot3\" ]), ) ) ddf . groupby ([ \"bene_id\" , \"hdr_icn\" ]) . apply ( agg_func , meta = { \"rot1\" : \"str\" , \"rot2\" : \"str\" , \"rot3\" : \"str\" } ) . compute () We can condense some of this code down by passing a list of columns to agg_func. import pandas as pd import dask.dataframe as dd import numpy as np def convert_dates_to_strings ( df , date_columns : list , date_format ) -> dd . DataFrame : for col in date_columns : df [ col ] = df [ col ] . dt . strftime ( date_format ) df [ col ] = df [ col ] . replace ( \"01011800\" , \"\" ) return df df = pd . DataFrame ( { \"bene_id\" : [ \"1\" , \"1\" , \"1\" , \"1\" , \"1\" ], \"hdr_icn\" : [ \"1\" , \"1\" , \"2\" , \"2\" , \"2\" ], \"rot1\" : [ \"A\" , \"B\" , \"C\" , \" \" , \"E\" ], \"rot2\" : [ \"X\" , \"Y\" , \"Z\" , \" \" , \" \" ], \"rot3\" : [ pd . to_datetime ( \"2018-01-01\" ), pd . to_datetime ( \"2018-01-01\" ), pd . to_datetime ( \"2018-01-01\" ), pd . to_datetime ( \"2018-01-01\" ), pd . to_datetime ( \"2018-01-01\" ), ], } ) ddf = dd . from_pandas ( df , 4 ) ddf = convert_dates_to_strings ( ddf , [ \"rot3\" ], \"%m %d %Y\" ) ddf = ddf . set_index ( \"bene_id\" ) . persist () def agg_func ( x , cols ): return pd . Series ({ col : \";\" . join ( x [ col ]) for col in cols }) ddf . groupby ([ \"bene_id\" , \"hdr_icn\" ]) . apply ( agg_func , [ \"rot1\" , \"rot2\" , \"rot3\" ]) . compute () We can further reduce runtime by providing agg_func with the expected \"meta\" output from .apply(...) import pandas as pd import dask.dataframe as dd import numpy as np def convert_dates_to_strings ( df , date_columns : list , date_format ) -> dd . DataFrame : for col in date_columns : df [ col ] = df [ col ] . dt . strftime ( date_format ) df [ col ] = df [ col ] . replace ( \"01011800\" , \"\" ) return df df = pd . DataFrame ( { \"bene_id\" : [ \"1\" , \"1\" , \"1\" , \"1\" , \"1\" ], \"hdr_icn\" : [ \"1\" , \"1\" , \"2\" , \"2\" , \"2\" ], \"rot1\" : [ \"A\" , \"B\" , \"C\" , \" \" , \"E\" ], \"rot2\" : [ \"X\" , \"Y\" , \"Z\" , \" \" , \" \" ], \"rot3\" : [ pd . to_datetime ( \"2018-01-01\" ), pd . to_datetime ( \"2018-01-01\" ), pd . to_datetime ( \"2018-01-01\" ), pd . to_datetime ( \"2018-01-01\" ), pd . to_datetime ( \"2018-01-01\" ), ], } ) ddf = dd . from_pandas ( df , 4 ) ddf = convert_dates_to_strings ( ddf , [ \"rot3\" ], \"%m %d %Y\" ) ddf = ddf . set_index ( \"bene_id\" ) . persist () def agg_func ( x , cols ): return pd . Series ({ col : \";\" . join ( x [ col ]) for col in cols }) # On a subset of data, pass the groupby object to dask.dataframe.utils.make_meta() ddf_meta = dd . utils . make_meta ( ddf . groupby ([ \"bene_id\" , \"hdr_icn\" ]) . apply ( agg_func , [ \"rot1\" , \"rot2\" , \"rot3\" ])) # You can view what you'll need to use as the meta object by accessing ddf_meta & ddf_meta.index >> ddf_meta Empty DataFrame Columns : [ rot1 , rot2 , rot3 ] Index : [] >> ddf_meta . index MultiIndex ( levels = [[ 'a' , 'b' ], [ 'foo' ]], codes = [[], []], names = [ 'bene_id' , 'hdr_icn' ]) # The ddf_meta object obviously wont be available @ runtime - we use the output to manually define # the object's properties typed_ddf_meta = pd . DataFrame ( columns = [ \"rot1\" , \"rot2\" , \"rot3\" ], index = pd . MultiIndex ( levels = [[ \"a\" , \"b\" ], [ \"foo\" ]], codes = [[], []], names = [ \"bene_id\" , \"hdr_icn\" ] ), ) typed_ddf_meta = ddf_meta . astype ( dtype = { \"rot1\" : \"str\" , \"rot2\" : \"str\" , \"rot3\" : \"str\" }) # note that the output of typed_ddf_meta and ddf_meta are equivalent # you can now pass typed_ddf_meta as the meta object to .apply() - you should notice a marginal speedup ddf . groupby ([ \"bene_id\" , \"hdr_icn\" ]) . apply ( agg_func , [ \"rot1\" , \"rot2\" , \"rot3\" ], meta = typed_ddf_meta ) . compute () It wouldn't make sense to run the .groupby() @ runtime, every time, to generate the meta_ddf information, so we'll define it by hand below: import pandas as pd import dask.dataframe as dd import numpy as np def convert_dates_to_strings ( df , date_columns : list , date_format ) -> dd . DataFrame : for col in date_columns : df [ col ] = df [ col ] . dt . strftime ( date_format ) df [ col ] = df [ col ] . replace ( \"01011800\" , \"\" ) return df df = pd . DataFrame ( { \"bene_id\" : [ \"1\" , \"1\" , \"1\" , \"1\" , \"1\" ], \"hdr_icn\" : [ \"1\" , \"1\" , \"2\" , \"2\" , \"2\" ], \"rot1\" : [ \"A\" , \"B\" , \"C\" , \" \" , \"E\" ], \"rot2\" : [ \"X\" , \"Y\" , \"Z\" , \" \" , \" \" ], \"rot3\" : [ pd . to_datetime ( \"2018-01-01\" ), pd . to_datetime ( \"2018-01-01\" ), pd . to_datetime ( \"2018-01-01\" ), pd . to_datetime ( \"2018-01-01\" ), pd . to_datetime ( \"2018-01-01\" ), ], } ) ddf = dd . from_pandas ( df , 4 ) ddf = convert_dates_to_strings ( ddf , [ \"rot3\" ], \"%m %d %Y\" ) ddf = ddf . set_index ( \"bene_id\" ) . persist () def agg_func ( x , cols ): return pd . Series ({ col : \";\" . join ( x [ col ]) for col in cols }) # Create ddf_meta object representing expected output from .apply() ddf_meta = pd . DataFrame ( columns = [ \"rot1\" , \"rot2\" , \"rot3\" ], index = pd . MultiIndex ( levels = [[ \"a\" , \"b\" ], [ \"foo\" ]], codes = [[], []], names = [ \"bene_id\" , \"hdr_icn\" ] ), ) ddf_meta = ddf_meta . astype ( dtype = { \"rot1\" : \"str\" , \"rot2\" : \"str\" , \"rot3\" : \"str\" }) # Pass ddf_meta to .apply(..., meta=ddf_meta) ddf . groupby ([ \"bene_id\" , \"hdr_icn\" ]) . apply ( agg_func , [ \"rot1\" , \"rot2\" , \"rot3\" ], meta = ddf_meta ) . compute ()","title":"Rotate Long Column Wide - Multiple"},{"location":"dask/dask.html#joining-on-index-separate-column","text":"","title":"Joining on Index + Separate Column"},{"location":"dask/dask.html#setup-data","text":"import pandas as pd import dask.dataframe as dd from io import StringIO ddf1_string = StringIO ( \"\"\"hdr_icn_num,ver,col1 1,1,foo 2,1,foo 3,1,foo 4,1,foo 5,1,foo \"\"\" ) ddf1 = dd . from_pandas ( pd . read_csv ( ddf1_string , sep = \",\" ), 5 ) ddf1 = ddf1 . set_index ( \"hdr_icn_num\" ) ddf2_string = StringIO ( \"\"\"hdr_icn_num,ver,col2,col3 1,1,bar!,baz 1,2,X,X 2,1,bar!, 2,2,X,X 3,1,bar!,baz 3,2,X,X 4,1,bar!, 4,2,X,X 5,1,bar!,baz 5,2,X,X \"\"\" ) ddf2 = dd . from_pandas ( pd . read_csv ( ddf2_string , sep = \",\" , keep_default_na = False ), 5 ) ddf2 = ddf2 . set_index ( \"hdr_icn_num\" ) ddf1 . head ( 10 , ddf1 . npartitions ) ddf2 . head ( 10 , ddf2 . npartitions )","title":"Setup Data"},{"location":"dask/dask.html#works","text":"join_df = dd . merge ( left = ddf1 , right = ddf2 , on = [ \"hdr_icn_num\" ], left_on = [ \"hdr_icn_num\" , \"ver\" ], right_on = [ \"hdr_icn_num\" , \"ver\" ], how = \"left\" , ) join_df . head ( 10 , join_df . npartitions )","title":"Works"},{"location":"dask/dask.html#works_1","text":"join_df = dd . merge ( left = ddf1 , right = ddf2 , left_on = [ \"hdr_icn_num\" , \"ver\" ], right_on = [ \"hdr_icn_num\" , \"ver\" ], how = \"left\" , ) join_df . head ( 10 , join_df . npartitions )","title":"Works"},{"location":"dask/dask.html#does-not-work","text":"join_df = dd . merge ( left = ddf1 , right = ddf2 , left_index = True , right_index = True , left_on = [ \"ver\" ], right_on = [ \"ver\" ], how = \"left\" , ) join_df . head ( 10 , join_df . npartitions )","title":"Does Not Work"},{"location":"dask/dask.html#task-scheduler-notes","text":"","title":"Task / Scheduler Notes"},{"location":"dask/dask.html#run-on-scheduler","text":"client.run_on_scheduler takes a custom function. The custom function should include an argument dask_scheduler if the custom function requires access to the Scheduler object and its API . client = Client ( \"etcetc\" ) # shows tasks on workers client . has_what () def get_task_stream ( dask_scheduler ): # Shows tasks that have been run/submitted in the past? return dask_scheduler . get_task_stream () def kill_task_across_clients ( dask_sheduler , task_key ): # Kill some task that exist w/some client # task_key == 'etc_etc-c07efb0ea6dd8c15df9a948ccd19e28c' for client in dask_scheduler . clients : dask_scheduler . cancel_key ( key = task_key , client = client ) task_stream = client . run_on_scheduler ( get_task_stream ) def user_info () -> dict : \"\"\" Returns dict of user information for the current process. Returns: Dict \"\"\" import os import getpass return dict ( uid = os . geteuid (), gid = os . getgid (), egid = os . getegid (), groups = os . getgroups (), user = getpass . getuser (), ) # Retrieve user info for the scheduler owner client . run_on_scheduler ( user_info ) user_info ()","title":"Run on Scheduler"},{"location":"kubernetes/edx.html","text":"Ch1. Container Orchestration \u00b6 Learning Objectives \u00b6 Define the concept of container orchestration. Explain the reasons for doing container orchestration. Can not provision underlying architecture. Discuss different container orchestration options. Discuss different container orchestration deployment options. Ch2. Kubernetes \u00b6 Define Kubernetes. \u00b6 \"Kubernetes is an open-source system for automating deployment, scaling, and management of containerized applications.\" k8s based on Google's Borg API Servers Pods IP-per-Pod Services Labels Written in Go Apache License Version 2.0 Google => CNCF July 2015 Explain the reasons for using Kubernetes. \u00b6 Discuss the features of Kubernetes. \u00b6 Automatic binpacking Kubernetes automatically schedules the containers based on resource usage - and constraints, without sacrificing the availability. Self-healing Kubernetes automatically replaces and reschedules the containers from failed nodes. It also kills and restarts the containers which do not respond to health checks, based on existing rules/policy. Horizontal scaling Kubernetes can automatically scale applications based on resource usage like CPU and memory. In some cases, it also supports dynamic scaling based on customer metrics. Service discovery and Load balancing Kubernetes groups sets of containers and refers to them via a Domain Name System (DNS). This DNS is also called a Kubernetes service. Kubernetes can discover these services automatically, and load-balance requests between - containers of a given service. Automated rollouts and rollbacks Kubernetes can roll out and roll back new versions/configurations of an application, without introducing any downtime. Secrets and configuration management Kubernetes can manage secrets and configuration details for an application without re-building the respective images. With secrets, we can share confidential information to our application without exposing it to the stack configuration, like on GitHub. Storage orchestration With Kubernetes and its plugins, we can automatically mount local, external, and storage solutions to the containers in a seamless manner, based on software-defined storage (SDS). Batch execution Besides long running jobs, Kubernetes also supports batch execution. Discuss the evolution of Kubernetes from Borg. \u00b6 Explain what the Cloud Native Computing Foundation does. \u00b6 One of the projects hosted by The Linux Foundation CNCF hosts a set of projects, with more to be added in the future. CNCF provides resources to each of the projects, but, at the same time, each project continues to operate independently under its pre-existing governance structure and with its existing maintainers. containerd for container runtime rkt for container runtime Kubernetes for container orchestration Linkerd for service mesh Envoy for service mesh gRPC for remote procedure call (RPC) Container Network Interface (CNI) for networking API CoreDNS for service discovery Rook for cloud-native storage Notary for security The Update Framework (TUF) for software updates Prometheus for monitoring OpenTracing for tracing Jaeger for distributed tracing Fluentd for logging Vitess for storage. For Kubernetes, the Cloud Native Computing Foundation: Provides a neutral home for the Kubernetes trademark and enforces proper usage Provides license scanning of core and vendored code Offers legal guidance on patent and copyright issues Creates open source curriculum , training , and certification Manages a software conformance working group Actively markets Kubernetes Hosts and funds developer marketing activities like K8Sport Supports ad hoc activities Funds conferences and meetup events. Ch3. Kubernets Architecture \u00b6 Terms: master worker nodes etcd Container Network Interface (CNI) Discuss the Kubernetes architecture. \u00b6 1+ Master Nodes 1+ Worker Nodes Distributed key-value store, like etcd If multiple Masters - only one in HA (High Availibility) mode. All Master nodes connect to etcd etcd is a distributed key-value store. KV store can be on Master, or separate with Master-KV connection. Explain the different components for master and worker nodes. \u00b6 Master \u00b6 API server \u00b6 accepts REST commands validates & processes commands After execution, state of cluster stored in distributed KV store. Scheduler \u00b6 schedules work to different worker nodes. resource usage information for each worker node. knows of user/operator-set constraints considers: quality of the service requirements data locality affinity anti-affinity etc schedules in terms of Pods and Services. Controller Manager \u00b6 manages non-termination control loops which regulate Kubernetes cluster state. Each control loop knows desired state of objects under management, watches state through API server. If current state != desired state then it corrects etcd \u00b6 distributed KV store stores cluster state Worker \u00b6 VM/Physical/etc running applications using Pods. Controlled by Master node. Pod is scheduling unit in k8s. Pod is logical connection of 1+ containers which are always scheduled together. Container runtime. \u00b6 Ex: containerd ; rkt ; lxd Docker is a platform which uses containerd as a container runtime. kubelet \u00b6 on each worker node - communicates with master node receives Pod definition (primarily thru API server) runs containers associated with Pod; keeps containers healthy connects to container runtime using Container Runtime Interface (CRI) CRI consists of protocol buffers, gRPC API, libraries kubelet (grpc client) connects to CRI shim (grpc server) - performs container/image operations. CRI two services: ImageService image-related operations. RuntimeService Pod & container-related operations. CRI allows k8s to use different container runtimes without need to recompile. CRI Shims dockershim containers created using Docker installed on worker nodes. Docker uses containerd to create/manage containers. cri-containerd containerd directly - no Docker. CRI-O enables using Open Container Initiative (OCI) compatibile runtimes. supports runC & Clear Containers Any OCI-compliant runtime can be plugged-in. kube-proxy \u00b6 Services group related Pods & load balances to them. network proxy on worker node listens to API server for Service endpoint creation/deletion. For each Service endpoint: kube-proxy sets up the routes Discuss about cluster state management with etcd. \u00b6 Stores cluster state. etcd is distributed Key-Value store based on Raft Concensus Algorithm collection of machines work as group to survive failure of some members. one node will be master, rest followers. Any node can be treated as master. written in Go stores config details: subnets; ConfigMaps; secrets; etc Review the Kubernetes network setup requirements. \u00b6 A unique IP is assigned to each Pod Two Primary Specifications: Container Network Model (CNM) - Docker Container Network Interface (CNI) - CoreOS k8s uses CNI container runtime relies on CNI for IP assignment. CNI connects to underlying configured plugin (Bridge or MACvlan) to get IPs. Plugin passes IPs to CNI which passes IP back to container runtime. Containers in a Pod can communicate to each other The Pod is able to communicate with other Pods in the cluster If configured, the application deployed inside a Pod is accessible from the external world. Container runtime creates isolated network for each container that it starts: network namespace Can be shared across Containers or Host OS. Inside Pod - containers share network namespace - can reach each other via localhost. Pod-to-Pod Communication Across Nodes Pods scheduled on any node. Pods need to communicate across nodes - all nodes should be able to reach any Pod. k8s ideal constraint: No Network Address Translation (NAT) during Pod-to-Pod communication across hosts ^^ Achieved: Routable Pods and nodes - uses underlying physical infrastructure like Google Kubernetes Engine. Software Defined Networking ( Flannel ; Weave ; Calico ; etc) Kubernetes Cluster Networking documentation Ch.4 Installing Kubernetes \u00b6 Discuss about the different Kubernetes configuration options. \u00b6 All-in-One Single-Node Installation \u00b6 With all-in-one, all the master and worker components are installed on a single node. This is very useful for learning, development, and testing. This type should not be used in production. Minikube is one such example, and we are going to explore it in future chapters. Single-Node etcd, Single-Master, and Multi-Worker Installation \u00b6 In this setup, we have a single master node, which also runs a single-node etcd instance. Multiple worker nodes are connected to the master node. Single-Node etcd, Multi-Master, and Multi-Worker Installation \u00b6 In this setup, we have multiple master nodes, which work in an HA mode, but we have a single-node etcd instance. Multiple worker nodes are connected to the master nodes. Multi-Node etcd, Multi-Master, and Multi-Worker Installation \u00b6 In this mode, etcd is configured in a clustered mode, outside the Kubernetes cluster, and the nodes connect to it. The master nodes are all configured in an HA mode, connecting to multiple worker nodes. This is the most advanced and recommended production setup. Discuss infrastructure considerations before installing Kubernetes. \u00b6 Should we set up Kubernetes on bare metal, public cloud, or private cloud? Which underlying system should we use? Should we choose RHEL, CoreOS, CentOS, or something else? Which networking solution should we use? etc Choosing the right solution Discuss infrastructure choices for a Kubernetes deployment. \u00b6 Localhost Installation \u00b6 Minikube Ubuntu on LXD On-Premise Installation \u00b6 On-Premise VMs k8s installed on VMs use Vagrant, VMware vSphere, KVM, etc Automate: Ansible / kubeadm On-Premise Bare Metal on top of OS RHEL, CoreOS, Fedora, Ubuntu, etc Cloud Installation \u00b6 Hosted Solutions \u00b6 Google Kubernetes Engine (GKE) Azure Container Service (AKS) Amazon Elastic Container Service for k8s (EKS) - Currently in Tech Preview OpenShift Dedicated Platform9 IBM Cloud Container Service Turnkey Cloud Solutions \u00b6 Google Compute Engine Amazon AWS Microsoft Azure Tectonic by CoreOS Bare Metal \u00b6 Various Cloud providers allow Bare Metal installations. Review Kubernetes installation tools and resources. \u00b6 kubeadm \u00b6 first-class citizen in k8s ecosystem. secure/recommended bootstrap of k8s. Contains building blocks to setup cluster. Easily extendable to add functionality. Does not provision machines KubeSpray \u00b6 (formerly name: Kargo) Purpose: Install Highly Available k8s cluster on: AWS, GCE, Azure, OpenStack, bare metal. based on Ansible. Available on most Linux distributions. Kubernets Incubator Project Kops \u00b6 Create/Destroy/Upgrade/Maintain production-grade, HA, k8s clusters from CLI. Can provision machines. AWS officially supported. GCE / VMware vSphere in alpha stage. ++platforms for future. Install k8s from scratch Kubernetes The Hard Way Ch.5 Setting Up a Single-Node k8s Cluster with Minikube \u00b6 Discuss Minikube. \u00b6 runsin VM on Linux/Mac/Windows. Requirements: kubectl binary used to access k8s cluster. Minikube requires kubectl installation to operate, but not to install. On Linux: VirtualBox or KVM hypervisors. On macOS: Hyperkit driver , xhyve driver , VirtualBox , or VMware Fusion hypervisors. On Windows: VirtualBox / Hyper-V hypervisors. VT-x/AMD-v virtualization enabled in BIOS. Internet access on first run. Install Minikube on Linux, Mac, and Windows. \u00b6 Start Here: Github Installation directions . Linux \u00b6 # Install VirtualBox sudo apt-get install virtualbox # Install Minikube curl -Lo minikube https://storage.googleapis.com/minikube/releases/v0.25.0/minikube-linux-amd64 && chmod +x minikube && sudo mv minikube /usr/local/bin/ # Validate Minikube installation minikube start minikube status minikube stop Mac \u00b6 Install VirtualBox on macOS # Install Minikube curl -Lo minikube https://storage.googleapis.com/minikube/releases/v0.25.0/minikube-darwin-amd64 && chmod +x minikube && sudo mv minikube /usr/local/bin/ # Validate Minikube installation minikube start minikube status minikube stop Windows \u00b6 Install VirtualBox Disable Hyper-V Windows support experimental Download the Minikube binary from the Distribution section. Add Minikube binary to $PATH. Set default VM driver for Minikube PS C : \\ Windows \\ system32 > minikube config set vm-driver virtualbox # These changes will take effect upon a minikube delete and then a minikube start Validate Installation PS C : \\ WINDOWS \\ system32 > minikube start PS C : \\ WINDOWS \\ system32 > minikube status PS C : \\ WINDOWS \\ system32 > minikube stop Ch.6 Accessing Minikube \u00b6 Review methods to access any Kubernetes cluster. \u00b6 Command Line Interface (CLI) \u00b6 kubectl Graphical User Interface (GUI) \u00b6 Kubernetes dashboard APIs. \u00b6 Three independent groups: Core Group (/api/v1) Pods, Services, nodes, etc Named Group objects in /apis/ NAME/ NAME/ VERSION format API versions imply levels of stability/support: Alpha - may be dropped @ any point in time, without notice. Ex: /apis/batch/v2alpha1 Beta - well-tested; semantics of objects may change Ex: /apis/certificates.k8s.io/v1beta1 Stable - appears in released software for many versions Ex: /apis/networking.k8s.io/v1 System-wide system-wide API endpoints Ex: /healthz ; /logs ; /metrcs ; /ui ; etc Configure kubectl for Linux, macOS, and Windows. \u00b6 Linux \u00b6 # Download latest stable kubectl binary curl -LO https://storage.googleapis.com/kubernetes-release/release/ $( curl -s https://storage.googleapis.com/kubernetes-release/release/stable.txt ) /bin/linux/amd64/kubectl # Make kubectl executable chmod +x ./kubectl # Move into PATH sudo mv ./kubectl /usr/local/bin/kubectl macOS \u00b6 # Download latest stable kubectl binary curl -LO https://storage.googleapis.com/kubernetes-release/release/ $( curl -s https://storage.googleapis.com/kubernetes-release/release/stable.txt ) /bin/darwin/amd64/kubectl # Make kubectl executable chmod +x ./kubectl # Move into PATH sudo mv ./kubectl /usr/local/bin/kubectl OR using Brew: brew install kubectl Windows \u00b6 DL latest kubectl release Depending on latest release, DL kubectl binary # Example download 1.9.3 curl -LO https://storage.googleapis.com/kubernetes-release/release/v1.9.3/bin/windows/amd64/kubectl.exe ` Once downloaded - move kubectl binary to PATH Access the Minikube dashboard. \u00b6 minikube dashboard or kubectl proxy - kubectl authenticates with API server on Master node - Makes dashboard available @ http://127.0.0.1:8001/api/v1/namespaces/kube-system/services/kubernetes-dashboard:/proxy/#!/overview?namespace=default - kubernetes-dashboard service runs inside kube-system namespace. Access Minikube via APIs. \u00b6 With kubectl proxy \u00b6 kubectl proxy In a new session: curl http://localhost:8001 Without kubectl proxy \u00b6 Use Bearer Token & kubectl Def: access token generated by authentication server (API server on master node) and given to client # Acquire Token TOKEN = $( kubectl describe secret -n kube-system $( kubectl get secrets -n kube-system | grep default | cut -f1 -d ' ' ) | grep -E '^token' | cut -f2 -d ':' | tr -d '\\t' | tr -d \" \" ) # Retrieve API server endpoint APISERVER = $( kubectl config view | grep https | cut -f 2 - -d \":\" | tr -d \" \" ) # Access API Server using curl curl $APISERVER --header \"Authorization: Bearer $TOKEN \" --insecure Ch.7 Kubernetes Building Blocks \u00b6 Review the Kubernetes object model. \u00b6 Object Model: what containerized apps are running on each node app resource consumption Policies attached to app (restart/upgrade, fault tolerance, etc) For each Object: dcl desired state using spec field. k8s manages status field for objects - state of object. k8s Control Plane always attempting to match desired state with actual state. Ex Objects: Pods, ReplicaSets, Deployments, Namespaces, etc To create Objects: Provide spec field to k8s API server. spec describes desired state & basic info (name, etc) JSON format usually define object's definition in .yaml file kubectl converts to JSON payload and sends to API server. TODO(Wes): Reduce > With the apiVersion field in the example above, we mention the API endpoint on the API server which we want to connect to. With the kind field, we mention the object type - in our case, we have Deployment. With the metadata field, we attach the basic information to objects, like the name. You may have noticed that in our example we have two spec fields (spec and spec.template.spec). With spec, we define the desired state of the deployment. In our example, we want to make sure that, at any point in time, at least 3 Pods are running, which are created using the Pods Template defined in spec.template. In spec.template.spec, we define the desired state of the Pod. Here, our Pod would be created using nginx:1.7.9. Discuss Labels and Selectors. \u00b6 Labels key-value pairs attached to k8s objects (e.g. Pods). organize & subset objects many objects -to- one label labels != unique to object Above Labels: app / env Label Selectors Equality-Based filter objects on Label keys and values = , == , != operators Ex: env==dev Set-Based filter objects on set of values in , notin , exists operators Ex: env in (dev, qa) Discuss Kubernetes building blocks \u00b6 Pods \u00b6 smallest k8s object. unit of deployment in k8s represents single instance of the app Pod is logical collection of 1+ containers, which: Are scheduled together on the same host Share the same network namespace Mount the same external storage (volumes). Ephemeral; can not self-heal use with controllers handle Pod's replication, fault tolerance, self-heal, etc Controller Ex: Deployments, ReplicaSets, ReplicationControllers, etc Pod Templates attach Pod's specificiation to other objects ReplicationController (rc) \u00b6 part of master node's controller manager. assures specified # replicas for Pod are running. controllers like rc always used to create/manage Pods. only supports equality-based Selectors. ReplicaSets \u00b6 next generation ReplicationController support both equality- and set-based selectors One Pod dies, current state != desired state ReplicaSet detects; creates Pod ReplicaSets can be independent; mostly used by Deployments to orchestrate Pod creation, deletion, updates. Deployments \u00b6 object automatically creates ReplicaSets. provides declarative updates to Pods and ReplicaSets. DeploymentController part of master node's controller manager. assures curret state == desired state. feature: Deployment recording (deployments explained below) if something goes wrong - rollback to previous state Below graphic: Deployment creates ReplicaSet A . ReplicaSet A creates 3 Pods . Each Pod - one container uses nginx:1.7.9 . Next graphic: in Deployment we change Pods Template & update image for nginx container to nginx:1.9.1 . Pod Template modified: new ReplicaSet B created. process referred to as Deployment rollout . rollout only triggered on Pods Template update for deployment. Scaling operations do not trigger deployment. Next graphic: When ReplicaSet B ready: Deployment points to it. Namespaces \u00b6 partitions k8s cluster. Ex: numerous users - organize into teams/projects. names of resources/objects created in Namespace are unique, but not across Namespaces . List all Namespaces : $ kubectl get namespaces NAME STATUS AGE default Active 11h kube-public Active 11h kube-system Active 11h k8s creates 2 default Namespaces: kube-system objects created by k8s system. default objects from any other Namespace. by default, we connect to default Namespace. kube-public readable by all users. used for special purposes (Ex: bootstrapping a cluster). Resource Quotas divide cluster resources within Namespaces. Ch.8 Authentication, Authorization, Admission Control \u00b6 Objective: Discuss authentication, authorization, and access control stages of the Kubernetes API access. Understand the different kinds of Kubernetes users. Discuss the different modules for authentication and authorization. Stages of k8s API access \u00b6 Authentication \u00b6 Logs in user. k8s does not have object user , or store usernames . k8s can use usernames for access control and request logging. Two kinds of users: Normal Users Managed outside k8s cluster via independent services, Ex: User/Client Certificates file listing usernames/passwords Google accounts etc Service Accounts in-cluster processes communicate with API server to perform operations. Most Service Account users auto-created via API server Can also create manually Service Account users tied to given Namespace mounts respective credentials to communicate with API server as Secrets. Authentication Modules \u00b6 Overview: Multiple authenticators can be enabled first module to successfully authenticate request short-circuits the evaluation. to be successful - enable at least 2 methods: service account tokens authenticator user authenticator k8s also supports anonymous requests , if configured Client Certificates enable w/reference to file w/1+ cert authorities pass --client-ca-file=SOMEFILE option to API server. cert auths in file validate client certs presented to API server. Demo Video: Static Token File pass file w/pre-defined bearer tokens pass with --token-auth-file=SOMEFILE option to API server. these tokens last indefinitely. cannot change w/o restarting API server Bootstrap Tokens alpha; used in bootstrapping new k8s cluster. Static Password File pass file w/basic authentication details pass w/ --basic-auth-file=SOMEFILE option to API server. lasts indefinitely change w/API server restart Service Account Tokens auto-enabled authenticator uses signed bearer tokens to verify requests tokens attached to Pods using ServiceAccount Admission Controller . allows in-cluster processes to talk to API server. OpenID Connect Tokens connect with OAuth 2 providers Ex: Azure Active Directory, Salesforce, Google, etc Webhook Token Authentication verification of bearer tokens offloaded to remote servce. Keystone Password pass --experimental-keystone-url=<AuthURL> option to API Server. AuthURL is Keystone server endpoint. Authenticating Proxy used to program additional authentication logic Authorization \u00b6 Authorizes API requests. After Authentication, users send API requests to perform operations. API requests are Authorized API request attributes authorized: user, group extra, Resource, Namespace, etc these attributes evaluated against policies. if evalualtion success - request allowed; otherwise denied. Multiple Authorization modules/authorizers. 1+ module can be configured for k8s cluster each module checked in sequence if any authorizer approves/denies - that decision is returned immediately. Authorization Modules \u00b6 Node Authorizer authorizes API requests from kubelets authorizes kubelet's: read operations for services, endpoints, nodes, etc write operators for nodes, pods, events, etc Kubernetes documentation Attribute-Based Access Control (ABAC) Authorizer k8s grants access to API requests - combine policies with attributes. Ex: user nkhare can only read Pods in Namespace lfs158 : { \"apiVersion\" : \"abac.authorization.kubernetes.io/v1beta1\" , \"kind\" : \"Policy\" , \"spec\" : { \"user\" : \"nkhare\" , \"namespace\" : \"lfs158\" , \"resource\" : \"pods\" , \"readonly\" : true } } enable w/ --authorization-mode=ABAC option to API server. specify authorization policy: --authorization-policy-file=PolicyFile.json Kubernetes documentation Webhook Authorizer k8s offers authorization decisions to 3 rd -party services enable: --authorization-webhook-config-file=SOME_FILENAME SOME_FILENAME: config of remote authorization service Kubernetes documentation Role-Based Access Control (RBAC) Authorizer regulate access to resources based on user assigned roles roles: users, service accounts, etc enable: --authorization-mode=RBAC to API server. Kubernetes documentation roles assigned operations: create , get , update , patch , etc operations known as \"verbs\" Two kids of roles: Role grant access to resource within specific Namespace kind: Role apiVersion: rbac.authorization.k8s.io/v1 metadata: namespace: lfs158 name: pod-reader rules: - apiGroups: [ \"\" ] # \"\" indicates the core API group resources: [ \"pods\" ] verbs: [ \"get\" , \"watch\" , \"list\" ] creates pod-reader role access only to Pods of lfs158 Namespace. ClusterRole grany access to resource with cluster-wide scope Once Role is created - bind users with RoleBinding RoleBinding bind users to same namespace as a Role. kind: RoleBinding apiVersion: rbac.authorization.k8s.io/v1 metadata: name: pod-read-access namespace: lfs158 subjects: - kind: User name: nkhare apiGroup: rbac.authorization.k8s.io roleRef: kind: Role name: pod-reader apiGroup: rbac.authorization.k8s.io user nkhare access to read Pods of lfs158 Namespace. ClusterRoleBinding grant access to resources @ cluster-level and to all Namespaces. Admission Control \u00b6 Modules which modify/reject requests based on additional checks: Ex: Quota Granular access control policies allowing privledged containers, checking resource quota, etc Resource Controllers: ResourceQuota, AlwaysAdmit, DefaultStorageClass, etc in effect only after API requests authenticated/authorized enable admission controls: start k8s API server w/ admission-control takes comma-delimited, ordered list of controller names --admission-control=NamespaceLifecyl,ResourceQuota,PodSecurityPolicy,DefaultStorageClass Kubernetes documentation Ch.9 Services \u00b6 Objective: \u00b6 Discuss the benefits of grouping Pods into Services to access an application. Explain the role of the kube-proxy daemon running on each worker node. Explore the Service discovery options available in Kubernetes. Discuss different Service types. Connecting Users to Pods \u00b6 IP's assigned dynamically - Pods are ephemeral. User/Client connected Pod dies - new Pod created. New Pod - New IP. k8s provides Services higher level abstraction than IP. groups Pods and policy to access them. grouping via Labels and Selectors . Services \u00b6 app keyword as Label. frontend & db values for Pods Selectors ( app==frontend & app==db ) groups into 2 logical groups: 1 w/3 Pods 1 w/1 Pod assign name to logical grouping: Service name . Ex: Two Services: frontend-svc selector: app==frontend db-svc selector: app==db Service Object Example \u00b6 kind: Service apiVersion: v1 metadata: name: frontend-svc spec: selector: app: frontend ports: - protocol: TCP port: 80 targetPort: 5000 Explain: Service: frontend-svc Selects Pods w/Label app==frontend Each Service receives IP address by default routable only inside cluster In Example: 172.17.0.4 for frontend-svc Service 172.17.0.5 for db-svc Service IP address attached to Service known as ClusterIP for that Service. User/Client connects to service via IP. Service forwards traffic to one of attached Pods. Service load balances while selecting the Pods for forwarding. can select Port to forward Ex: frontend-svc receives requests from user/client on Port 80 . frontend-svc forwards to Pod on Port 5000 . If no port designated: Service forwards on same port received Service endpoint tuple of Pods, IP, targetPort Ex: frontend-svc has 3 endpoints: 10.0.1.3:5000 10.0.1.4:5000 10.0.1.5:5000 kube-proxy \u00b6 worker nodes run daemon called kube-proxy watches API server on master node for addition/removal of Services/endpoints. For each new Service, on each node, kube-proxy configures iptables to capture traffic for its ClusterIP & forwards to one of the endpoints. When Service removed: kube-proxy removes iptables rules on all nodes as well. Service Discovery \u00b6 Two methods for discovering Services: Environment Variables @Pod Start, kubelet daemon on node adds env variables in Pod for all active Services. Ex: Service: redis-master ; exposes port 6379 ClusterIP 172.17.0.6 then, new Pod: REDIS_MASTER_SERVICE_HOST = 172 .17.0.6 REDIS_MASTER_SERVICE_PORT = 6379 REDIS_MASTER_PORT = tcp://172.17.0.6:6379 REDIS_MASTER_PORT_6379_TCP = tcp://172.17.0.6:6379 REDIS_MASTER_PORT_6379_TCP_PROTO = tcp REDIS_MASTER_PORT_6379_TCP_PORT = 6379 REDIS_MASTER_PORT_6379_TCP_ADDR = 172 .17.0.6 Note : Pods will not have env variables for Services created after Pod creation. DNS most common; recommended. addon for DNS . creates DNS record for each Service format: my-svc.my-namespace.svc.cluster.local Services w/same Namespace can talk. Ex: Service: redis-master in my-ns Namespace. All Pods in same Namespace can reach redis Service by using its name: redis-master Pods from other Namespaces can reach redis-master Service, by: Add respective Namespace as suffix: redis-master.my-ns . ServiceType \u00b6 Access scope decided by ServiceType - can be mentioned when creating Service. Is the Service: only accessible within the cluster? accessible from within the cluster and the external world? Maps to an external entity which resides outside the cluster? ClusterIP \u00b6 default ServiceType Service receives Virtual IP using ClusterIP. assigned IP used for communicating w/Service accessible only within Cluster. NodePort \u00b6 in addition to creating ClusterIP: port range 30000-32767 mapped to respective Service, from all worker nodes. Ex: mapped NodePort: 32233 for service frontend-svc connect to any worker node on 32233 node redirects all traffic to ClusterIP - 172.17.0.4 Default: when expose NodePort => random port auto-selected by k8s Master from range 30000-32767 . can assign specific port to avoid dynamic port value while creating service. NodePort ServiceType can make Services accessible to external world. end-user connects to worker nodes on specified port worker node forwards traffic to apps running inside cluster. admins can configure reverse proxy outside k8s cluster map specific endpoint to respective port on worker nodes LoadBalancer \u00b6 NodePort & ClusterIP Services automatically created external load balancer will route to them Services exposed @ static port on each worker node Service exposed externally w/underlying cloud provider's load balance feature. LoadBalancer ServiceType only works if: underlying IaaS supports automatic creation of Load Balancers and support in k8s (GCP/AWS) ExternalIP \u00b6 Service mapped to ExternalIP if it can route to one or more worker nodes. Traffic ingressed with ExternalIP (as destination IP) on Service port is routed to one of the Service endpoints. Note: ExternalIPs not managed by k8s. cluster admins configure routing to map ExternalIP address to one of the nodes. ExternalName \u00b6 ExternalName special ServiceType no Selectors does not define any endpoints when accessed within cluster: returns CNAME record of externally configured Service. make externally configured Services ( my-database.example.com ) available inside cluster requires just the name (like, my-database ) available inside same Namespace Ch.10 Deploying a Stand-Alone Application \u00b6 Objective: Deploy an application from the dashboard. Deploy an application from a YAML file using kubectl. Expose a service using NodePort. Access the application from the external world. Minikube GUI \u00b6 minikube start minikube status minikube dashboard Deploy webserver usign nginx:alpine image: Dashboard: click: CREATE Tab: CREATE AN APP Enter as seen: Click: DEPLOY kubectl CLI \u00b6 kubectl get deployments kubectl get replicasets kubectl get pods Labels / Selectors \u00b6 kubectl describe pod webserver-74d8bd488f-xxxxx kubectl get pods -L k8s-app,label2 # -L option = add additional columns in output kubectl get pods -l k8s-app = webserver # -l option = selector Delete Deployment \u00b6 kubectl delete deployments webserver # Also deletes ReplicaSets & Pods Deployment YAML \u00b6 Create webserver.yaml # webserver.yaml apiVersion: apps/v1 kind: Deployment metadata: name: webserver labels: app: nginx spec: replicas: 3 selector: matchLabels: app: nginx template: metadata: labels: app: nginx spec: containers: - name: nginx image: nginx:alpine ports: - containerPort: 80 kubectl create -f webserver.yaml Create / Expose w/NodePort \u00b6 ServiceTypes : define access method for given Service. With NodePort ServiceType k8s opens static port on all worker nodes. Connect to open static port from any node - forwarded to respective Service. Create webserver-svc.yaml : # webserver-svc.yaml apiVersion: v1 kind: Service metadata: name: web-service labels: run: web-service spec: type: NodePort ports: - port: 80 protocol: TCP selector: app: nginx kubectl create -f webserver-svc.yaml kubectl get svc NAME TYPE CLUSTER-IP EXTERNAL-IP PORT ( S ) AGE kubernetes ClusterIP 10 .96.0.1 <none> 443 /TCP 4d web-service NodePort 10 .108.132.106 <none> 80 :31791/TCP 3m ClusterIP: 10.108.132.106 Port: 80:31791 We've reserved static port 31791 on node. If connect to node on that port - request forwarded to ClusterIP on port 80. Deployment / Service creation can happen in any order. kubectl describe svc web-service web-service uses app=nginx as Selector, which selects the three Pods - listed as endpoints. So, whenever a request is sent to our Service - served by one of Pods listed in Endpoints section. Access App Using Exposed NodePort \u00b6 minikube ip Open browser @ listed IP and kubectl describe svc web-service NodePort. or , at CLI: minikube service web-service Liveness / Readiness Probes \u00b6 Kubernetes documentation Liveness Probe checks application health if fails - restarts container Set by Defining: Liveness Command Liveness HTTP request TCP Liveness Probe Liveness Command \u00b6 Check existence of file /tmp/healthy : # liveness-exec.yaml apiVersion: v1 kind: Pod metadata: labels: test: liveness name: liveness-exec spec: containers: - name: liveness image: k8s.gcr.io/busybox args: - /bin/sh - -c - touch /tmp/healthy; sleep 30; rm -rf /tmp/healthy; sleep 600 livenessProbe: exec: command: - cat - /tmp/healthy initialDelaySeconds: 3 periodSeconds: 5 kubectl create -f liveness-exec.yaml kubectl get pods kubectl describe pod liveness-exec - periodSeconds: tmp/healthy checked every 5 seconds. - initialDelaySeconds: requests kubelet to wait 3 seoncds before first probe. Liveness HTTP Request \u00b6 kubelet sends HTTP GET request to /healthz endpoint of application on port 8080. # liveness-http.yaml apiVersion: v1 kind: Pod metadata: labels: test: liveness name: liveness-exec spec: containers: - name: liveness image: k8s.gcr.io/busybox args: - /bin/sh - -c - touch /tmp/healthy ; sleep 30 ; rm -rf /tmp/healthy ; sleep 600 livenessProbe: httpGet: path: /healthz port: 8080 httpHeaders: - name: X-Custom-Header value: Awesome initialDelaySeconds: 3 periodSeconds: 3 TCP Liveness Probe \u00b6 kubelet attempts to open TCP socket to the container running application. # liveness-tcp.yaml apiVersion: v1 kind: Pod metadata: labels: test: liveness name: liveness-exec spec: containers: - name: liveness image: k8s.gcr.io/busybox args: - /bin/sh - -c - touch /tmp/healthy ; sleep 30 ; rm -rf /tmp/healthy ; sleep 600 livenessProbe: tcpSocket: port: 8080 initialDelaySeconds: 15 periodSeconds: 20 Readiness Probes \u00b6 Application must meet conditions before receiving traffic. # readiness-probe.yaml apiVersion: v1 kind: Pod metadata: labels: test: readiness name: readiness-exec spec: containers: - name: readiness image: k8s.gcr.io/busybox args: - /bin/sh - -c - sleep 20 ; touch /tmp/healthy ; sleep 20 ; rm -rf /tmp/healthy ; sleep 600 readinessProbe: exec: command: - cat - /tmp/healthy initialDelaySeconds: 5 periodSeconds: 5 Ch.11 Kubernetes Volume Management \u00b6 Explain the need for persistent data management. Discuss Kubernetes Volume and its types. Discuss PersistentVolumes and PersistentVolumeClaims. Volumes \u00b6 Containers, and their data, are ephemeral. Solve with Volumes. Volume attached to a Pod, shared among containers in Pod. Volume has same life span as Pod. Outlives containers of Pod. Data preserved across container restart. Volume Types \u00b6 Directory mounted in Pod backed by underlying Volume Type - decides properties of directory (size, content, etc). emptyDir empty Volume created for Pod as soon as it's scheduled on worker node. Volume life coupled with Pod. Pod dies - content of emptyDir deleted. hostPath share a directory from the host to Pod. Pod dies - content of Volume available on host. gcePersistentDisk mount Google Compute Engine (GCE) persistent disk into Pod. awsElasticBlockStore mount AWS EBS Volume into Pod. nfs mount NFS share into Pod. iscsi mount iSCSI share into Pod. secret pass sensitive information (passwords) to Pods. persistentVolumeClaim attach PersistentVolume to Pod. Kubernetes Volume Types Persistent Volumes \u00b6 Network-attached storage in the cluster - provisioned by admin. PersistentVolume (PV) subsystem provides APIs for users/admins to manage / consume storage. Manage: PersistentVolume API resource type. Consume: PersistentVolumeClaim API resource type. PersistentVolumes can be dynamically provisioned based on StorageClass resource. StorageClass contains pre-defined provisioners and parameters to create a PersistentVolume. Using PersistentVolumeClaims: User sends request for dynamic PV creation. wired to StorageClass resource. Volume Types that support managing using PersistentVolumes: GCEPersistentDisk AWSElasticBlockStore AzureFile NFS iSCSI Complete List: Kubernetes Documentation PersistentVolumeClaims \u00b6 PersistentVolumeClaim (PVC) is user request for storage. User requests for PersistentVolume resources based on size, access models, etc. Once suitable PersistentVolume is found: bound to a PersistentVolumeClaim. After successful bound, PersistentVolumeClaim resource can be used in Pod. When finished - attached PersistentVolumes can be released, reclaimed, recycled. See Kubernetes Documentation . Container Storage Interface (CSI) \u00b6 Container orchestrators (k8s, Mesos, Docker, etc) each have unqiue method of managing external storage using Volumes. Storage Vendors can't keep up with differences. Let's standardize! Container Storage Interface specifications . Ch.12 Deploying a Multi-Tier Application \u00b6 Analyze a sample multi-tier application. Deploy a multi-tier application. Scale an application. RSVP Application \u00b6 users register for event. provide username/email. name/email goes in table. App: backend database: MongoDB frontend: Python Flask-based Code: github - rsvp.py - look for MONGODB_HOST env variable for db endpoint. - connect to it on port 27017 MONGODB_HOST = os.environ.get ( 'MONGODB_HOST' , 'localhost' ) client = MongoCLient ( MONGODB_HOST, 27017 ) Deploy with 1 backend / 1 frontend then, scale Backend \u00b6 # rsvp-db.yaml apiVersion: apps/v1 kind: Deployment metadata: name: rsvp-db labels: appdb: rsvpdb spec: replicas: 1 selector: matchLabels: appdb: rsvpdb template: metadata: labels: appdb: rsvpdb spec: containers: - name: rsvp-db image: mongo:3.3 ports: - containerPort: 27017 kubectl create -f rsvp-db.yaml Create mongodb service. # rsvp-db-service.yaml apiVersion: v1 kind: Service metadata: name: mongodb labels: app: rsvpdb spec: ports: - port: 27017 protocol: TCP selector: appdb: rsvpdb kubectl create -f rsvp-db-service.yaml did not specify ServiceType mongodb has default ClusterIP ServiceType . mongodb will not be accessible from external world. kubectl get deployments kubectl get services Frontend \u00b6 using Python Flask-based microframework source: https://raw.githubusercontent.com/cloudyuga/rsvpapp/master/rsvp.py Docker image: teamcloudyuga/rsvpapp Dockerfile to create teamcloudyuga/rsvpapp: https://raw.githubusercontent.com/cloudyuga/rsvpapp/master/Dockerfile Create Deployment for rsvp Frontend. # rsvp-web.yaml apiVersion: apps/v1 kind: Deployment metadata: name: rsvp labels: app: rsvp spec: replicas: 1 selector: matchLabels: app: rsvp template: metadata: labels: app: rsvp spec: containers: - name: rsvp-app image: teamcloudyuga/rsvpapp env: - name: MONGODB_HOST value: mongodb ports: - containerPort: 5000 name: web-port kubectl create -f rsvp-web.yaml passing name of MongoDB Service, mongodb , as env variable. expected by frontend Note Ports: containerPort 5000 name: web-port Can change underlying containerPort without making changes Service. Create Service for rsvp Frontend. # rsvp-web-service.yaml apiVersion: v1 kind: Service metadata: name: rsvp labels: app: rsvp spec: type: NodePort ports: - port: 80 targetPort: web-port protocol: TCP selector: app: rsvp kubectl create -f rsvp-web-service.yaml Note: targetPort in ports section. forwards requests on port 80 for ClusterIP to web-port port (5000) on connected Pods. Look @ available deployments and services: kubectl get deployments kubectl get services Access RSVP Application \u00b6 minikube ip # NodePort Port kubectl get services OR minikube service rsvp Scale Frontend \u00b6 Scale from 1 to 4 replicas: kubectl scale deployment rsvp --replicas = 3 kubectl get deployments Refreshing site will show multiple Host: rsvp-xxx-xxx as routed to different endpoints. Ch.13 ConfigMaps and Secrets \u00b6 Discuss configuration management for applications in Kubernetes using ConfigMaps. Share sensitive data (such as passwords) using Secrets. ConfigMaps \u00b6 decouples config details from container image. pass as key-value pairs later consumed by Pods, controllers, other system components, etc. Create by: literal value files Create ConfigMap @ CLI \u00b6 kubectl create configmap my-config --from-literal = key1 = value1 --from-literal = key2 = value2 Get ConfigMap Details \u00b6 kubectl get configmaps my-config -o yaml Create ConfigMap from file. \u00b6 # customer1-configmap.yaml apiVersion: v1 kind: ConfigMap metadata: name: customer1 data: TEXT1: Customer1_Company TEXT2: Welcomes You COMPANY: Customer1 Company Technology Pct. Ltd. kubectl create -f customer1-configmap.yaml Use ConfigMap in Pods \u00b6 While creating deployment - assign values for env variables from customer1 ConfigMap: # container .... containers: - name: rsvp-app image: teamcloudyuga/rsvpapp env: - name: MONGODB_HOST value: mongodb - name: TEXT1 valueFrom: configMapKeyRef: name: customer1 key: TEXT1 - name: TEXT2 valueFrom: configMapKeyRef: name: customer1 key: TEXT2 - name: COMPANY valueFrom: configMapKeyRef: name: customer1 key: COMPANY .... TEXT1 env var: \"Customer1_Company\" TEXT2 env var: \"Welcomes You\" Mount ConfigMap as Volume \u00b6 Kubernetes documentation on ConfigMaps . For Each key: file in mount path is key content of file becomes value Secrets \u00b6 Shares sensitive info (pws, tokens, keys) passed as key-value pairs Secret objects are referenced in Deployments. Secret data stored as plain text inside etcd . kubectl create secret generic my-password --from-literal = password = my3q1p@ssw0rd kubectl get secret my-password kubectl describe secret my-password Create Secret Manually \u00b6 With Secrets, each object must be encoded using base64. echo mysqlpassword | base64 Use base64 encoded password in config file: # my-password.yaml apiVersion: v1 kind: Secret metadata: name: my-password type: Opaque data: password: bXlzcWxwYXNzd29yZAo = base64 != encryption: echo \"bXlzcWxwYXNzd29yZAo=\" | base64 --decode Use Secrets Inside Pods \u00b6 expose as env variable or mount as data volume Environment Variable \u00b6 Reference a Secret & assign value of its key as env variable WORDPRESS_DB_PASSWORD : ..... spec: containers: - image: wordpress:4.7.3-apache name: wordpress env: - name: WORDPRESS_DB_HOST value: wordpress-mysql - name: WORDPRESS_DB_PASSWORD valueFrom: secretKeyRef: name: my-password key: password ..... Mount as Volume \u00b6 Secrets as Files from Pod: mount Secret as Volume inside Pod. file created for each key in Secret contents = value Kubernetes documentation Ch.14 Ingress \u00b6 Objective: Explain what Ingress and Ingress Controllers are. Learn when to use Ingress. Access an application from the external world using Ingress. Ingress allows updates to app w/o worrying about external access. \"An Ingress is a collection of rules that allow inbound connections to reach the cluster Services.\" Ingress configures Layer 7 HTTP load balancer for Services. Provides: TLS (Transport Layer Security) Name-based virtual hosting Path-based routing Custom roles Users don't connect directly to Service. Users reach Ingress endpoint, forwarded to respective Service. # webserver-ingress.yaml apiVersion: extensions/v1beta1 kind: Ingress metadata: name: web-ingress namespace: default spec: rules: - host: blue.example.com http: paths: - backend: serviceName: webserver-blue-svc servicePort: 80 - host: green.example.com http: paths: - backend: serviceName: webserver-green-svc servicePort: 80 Above, Example of Name-Based Virtual Hosting Ingress rule: User requests to both blue.example.com & green.example.com routed to same Ingress endpoint. forwarded to webserver-blue-svc & webserver-green-svn , respectively. Below, Example of Fan Out Ingress rules: requests: example.com/blue & example.com/green forwarded: webserver-blue-svc & webserver-green-svc , respectively. Ingress Controller \u00b6 Ingress Controller watches Master Node's API server for changes in Ingress resources updates Layer 7 Load Balancer accordingly. k8s has several Ingress Controllers: GCE L7 Load Balancer Nginx Ingress Controller can also build your own Start Ingress Controller w/Minikube \u00b6 Minikube v0.14.0+ contains Nginx Ingress Controller setup as addon: minikube addons enable ingress Deploy Ingress Resource \u00b6 # webserver-ingress.yaml apiVersion: extensions/v1beta1 kind: Ingress metadata: name: web-ingress namespace: default spec: rules: - host: blue.example.com http: paths: - backend: serviceName: webserver-blue-svc servicePort: 80 - host: green.example.com http: paths: - backend: serviceName: webserver-green-svc servicePort: 80 kubectl create -f webserver-ingress.yaml Access Services Using Ingress \u00b6 Should now have access to: webserver-blue-svc & webserver-green-svc via blue.example.com & green.example.com Setup on Minikube (local VM), update host config file ( /etc/hosts on Mac/Linux): minikube ip 192 .168.99.100 cat /etc/hosts 127 .0.0.1 localhost ::1 localhost 192 .168.99.100 blue.example.com green.example.com Ch.15 Advanced Topics \u00b6 Annotations \u00b6 Attach arbitrary non-identifying metadata to any objects, K-V \"annotations\" : { \"key1\" : \"value1\" , \"key2\" : \"value2\" } Not used to ID/select objects, instead: Store buid/release IDs, PR numbers, git branch ,etc Phone/pager numbers of people responsible, directory entries specifying where that info can be found Pointers to logging, monitoring, analytics, audit repositories, debugging tools, etc. Etc Ex: While Create Deployment, add description like: apiVersion : extensions/v1beta1 kind : Deployment metadata : name : webserver annotations : description : Deployment based PoC dates 2nd June'2017 .... Look @ annotations while describing object: kubectl describe deployment webserver Name: webserver Namespace: default CreationTimestamp: Sat, 03 Jun 2017 05 :10:38 +0530 Labels: app = webserver Annotations: deployment.kubernetes.io/revision = 1 description = Deployment based PoC dates 2nd June ' 2017 ... Deployment Features \u00b6 Record Deployment, revert if wrecks. If recorded Deployment before update, revert back to known working state: Deployment Object also provides: Autoscaling Proportional scaling Pausing and resuming. Jobs \u00b6 Creates 1+ Pods to perform task. Job object takes responsibility of Pod failures. Assures task completed successfully. Task complete - Pods terminate automatically. Can be scheduled for times/dates. CronJob Quota Management \u00b6 ResourceQuota object. Provides contraints that limit aggregate resource consumption per Namespace. Types of Quotas per Namespace: Compute Resource Quota limit total sum of compute resources (CPU, memory, etc) which can be requested in Namespace. Storage Resource Quota Limit sum of storage resources (PersistentVolumeClaims, requests.storage, etc). Object Count Quota Restrict # objects of given type (Pods, ConfigMaps, PersistentVolumeClaims, ReplicationControllers, Services, Secrets, etc). DaemonSets \u00b6 DaemonSet object allows: collecting monitoring data from all nodes. running storage daemon on all nodes. etc. specific type of Pod running on all nodes at all times. When Node added to Cluster: Pod from given DaemonSet created on it. When Node dies Respective Pods garbage collected. If DaemonSet deleted - all Pods it created are deleted as well. StatefulSets \u00b6 StatefulSet controller used for apps requiring unique identity: name network identifications strict ordering etc, Ex: MySQL cluster , etcd cluster Provides ID and guaranteed ordering of deployment and scaling of Pods. Kubernetes Cluster Federation \u00b6 Manage multiple k8s clusters from single control plane. Sync resources across clusters & cross-cluster discovery. Allows Deployments across regions, and access using global DNS record. Useful w/hybrid solutions: Cluster inside private datacenter. and Cluster on public cloud. Can assign weights for each cluster in the Federation - distribute load. Custom Resources \u00b6 A resource is an API endpoint which stores a collection of API objects. Ex: Pod resource contains all Pod objects. k8s existing resources fullfill most requirements. Can create new resources using custom resources dynamic in nature appear/disappear in already running cluster @ anytime. Make resource declarative: create/install custom controller interprets resource structure performs required actions can be deployed/managed in pre-running clusters Two Methods to Add Custom Resources: Custom Resource Definitions (CRDs) Easiest doesn't require programming knowledge building custom controller would require some programming API Aggregation Fine grained control subordinate API servers sit behind primary API server & act as proxy Helm \u00b6 k8s manifests: Deployments Services Volume Claims Ingress etc Chart Can bundle manifests after templatizing them into well-defined format, along with other metadata. can be served via repositories like rpm & deb packages. Helm: Package manager (like yum & apt ) for k8s. install/update/delete Charts in k8s cluster. Two components: Client - Helm - runs on user's workstation. Server - tiller - runs inside k8s cluster. Client helm connects to server tiller to manage Charts. Github Helm Charts Monitoring and Logging \u00b6 Collect resource usage data by Pods, Services, nodes, etc to determine scaling decisions. Heapster cluster-wide aggregator of monitoring & event data native k8s support Prometheus part of CNCF can be used to gather resource usage from k8s components and objects. Using client libraries - can instrument code of app. Logging important for debugging - collected from objects, nodes, etc. Elasticsearch Uses fluentd w/custom config as an agent on nodes. open source data collector. part for CNCF. Ch.16 Community \u00b6 Understand the importance of Kubernetes community. Learn about the different channels to interact with the Kubernetes community. List major CNCF events. K8sPort - recognizes / rewards community members Weekly Meetings using video conference tools. https://groups.google.com/forum/#!forum/kubernetes-community-video-chat Meetup Groups https://www.meetup.com/topics/kubernetes/ Slack Channels: #kubernetes-users Mailing Lists Users Developers Special Interest Groups Scheduling, authorization, networking, documentation, etc Existing SIGs New SIG Creation Stack Overflow CNCF Events Three of the major conferences it organizes are: KubeCon + CloudNativeCon Europe KubeCon + CloudNativeCon North America KubeCon + CloudNativeCon China. Next Course: - Kubernetes Fundamentals - Kubernetes Administrator - Certified Kubernetes Adminsitrator Exam - Certified Kubernetes Application Developer Program","title":"EDx"},{"location":"kubernetes/edx.html#ch1-container-orchestration","text":"","title":"Ch1. Container Orchestration"},{"location":"kubernetes/edx.html#learning-objectives","text":"Define the concept of container orchestration. Explain the reasons for doing container orchestration. Can not provision underlying architecture. Discuss different container orchestration options. Discuss different container orchestration deployment options.","title":"Learning Objectives"},{"location":"kubernetes/edx.html#ch2-kubernetes","text":"","title":"Ch2. Kubernetes"},{"location":"kubernetes/edx.html#define-kubernetes","text":"\"Kubernetes is an open-source system for automating deployment, scaling, and management of containerized applications.\" k8s based on Google's Borg API Servers Pods IP-per-Pod Services Labels Written in Go Apache License Version 2.0 Google => CNCF July 2015","title":"Define Kubernetes."},{"location":"kubernetes/edx.html#explain-the-reasons-for-using-kubernetes","text":"","title":"Explain the reasons for using Kubernetes."},{"location":"kubernetes/edx.html#discuss-the-features-of-kubernetes","text":"Automatic binpacking Kubernetes automatically schedules the containers based on resource usage - and constraints, without sacrificing the availability. Self-healing Kubernetes automatically replaces and reschedules the containers from failed nodes. It also kills and restarts the containers which do not respond to health checks, based on existing rules/policy. Horizontal scaling Kubernetes can automatically scale applications based on resource usage like CPU and memory. In some cases, it also supports dynamic scaling based on customer metrics. Service discovery and Load balancing Kubernetes groups sets of containers and refers to them via a Domain Name System (DNS). This DNS is also called a Kubernetes service. Kubernetes can discover these services automatically, and load-balance requests between - containers of a given service. Automated rollouts and rollbacks Kubernetes can roll out and roll back new versions/configurations of an application, without introducing any downtime. Secrets and configuration management Kubernetes can manage secrets and configuration details for an application without re-building the respective images. With secrets, we can share confidential information to our application without exposing it to the stack configuration, like on GitHub. Storage orchestration With Kubernetes and its plugins, we can automatically mount local, external, and storage solutions to the containers in a seamless manner, based on software-defined storage (SDS). Batch execution Besides long running jobs, Kubernetes also supports batch execution.","title":"Discuss the features of Kubernetes."},{"location":"kubernetes/edx.html#discuss-the-evolution-of-kubernetes-from-borg","text":"","title":"Discuss the evolution of Kubernetes from Borg."},{"location":"kubernetes/edx.html#explain-what-the-cloud-native-computing-foundation-does","text":"One of the projects hosted by The Linux Foundation CNCF hosts a set of projects, with more to be added in the future. CNCF provides resources to each of the projects, but, at the same time, each project continues to operate independently under its pre-existing governance structure and with its existing maintainers. containerd for container runtime rkt for container runtime Kubernetes for container orchestration Linkerd for service mesh Envoy for service mesh gRPC for remote procedure call (RPC) Container Network Interface (CNI) for networking API CoreDNS for service discovery Rook for cloud-native storage Notary for security The Update Framework (TUF) for software updates Prometheus for monitoring OpenTracing for tracing Jaeger for distributed tracing Fluentd for logging Vitess for storage. For Kubernetes, the Cloud Native Computing Foundation: Provides a neutral home for the Kubernetes trademark and enforces proper usage Provides license scanning of core and vendored code Offers legal guidance on patent and copyright issues Creates open source curriculum , training , and certification Manages a software conformance working group Actively markets Kubernetes Hosts and funds developer marketing activities like K8Sport Supports ad hoc activities Funds conferences and meetup events.","title":"Explain what the Cloud Native Computing Foundation does."},{"location":"kubernetes/edx.html#ch3-kubernets-architecture","text":"Terms: master worker nodes etcd Container Network Interface (CNI)","title":"Ch3. Kubernets Architecture"},{"location":"kubernetes/edx.html#discuss-the-kubernetes-architecture","text":"1+ Master Nodes 1+ Worker Nodes Distributed key-value store, like etcd If multiple Masters - only one in HA (High Availibility) mode. All Master nodes connect to etcd etcd is a distributed key-value store. KV store can be on Master, or separate with Master-KV connection.","title":"Discuss the Kubernetes architecture."},{"location":"kubernetes/edx.html#explain-the-different-components-for-master-and-worker-nodes","text":"","title":"Explain the different components for master and worker nodes."},{"location":"kubernetes/edx.html#master","text":"","title":"Master"},{"location":"kubernetes/edx.html#api-server","text":"accepts REST commands validates & processes commands After execution, state of cluster stored in distributed KV store.","title":"API server"},{"location":"kubernetes/edx.html#scheduler","text":"schedules work to different worker nodes. resource usage information for each worker node. knows of user/operator-set constraints considers: quality of the service requirements data locality affinity anti-affinity etc schedules in terms of Pods and Services.","title":"Scheduler"},{"location":"kubernetes/edx.html#controller-manager","text":"manages non-termination control loops which regulate Kubernetes cluster state. Each control loop knows desired state of objects under management, watches state through API server. If current state != desired state then it corrects","title":"Controller Manager"},{"location":"kubernetes/edx.html#etcd","text":"distributed KV store stores cluster state","title":"etcd"},{"location":"kubernetes/edx.html#worker","text":"VM/Physical/etc running applications using Pods. Controlled by Master node. Pod is scheduling unit in k8s. Pod is logical connection of 1+ containers which are always scheduled together.","title":"Worker"},{"location":"kubernetes/edx.html#container-runtime","text":"Ex: containerd ; rkt ; lxd Docker is a platform which uses containerd as a container runtime.","title":"Container runtime."},{"location":"kubernetes/edx.html#kubelet","text":"on each worker node - communicates with master node receives Pod definition (primarily thru API server) runs containers associated with Pod; keeps containers healthy connects to container runtime using Container Runtime Interface (CRI) CRI consists of protocol buffers, gRPC API, libraries kubelet (grpc client) connects to CRI shim (grpc server) - performs container/image operations. CRI two services: ImageService image-related operations. RuntimeService Pod & container-related operations. CRI allows k8s to use different container runtimes without need to recompile. CRI Shims dockershim containers created using Docker installed on worker nodes. Docker uses containerd to create/manage containers. cri-containerd containerd directly - no Docker. CRI-O enables using Open Container Initiative (OCI) compatibile runtimes. supports runC & Clear Containers Any OCI-compliant runtime can be plugged-in.","title":"kubelet"},{"location":"kubernetes/edx.html#kube-proxy","text":"Services group related Pods & load balances to them. network proxy on worker node listens to API server for Service endpoint creation/deletion. For each Service endpoint: kube-proxy sets up the routes","title":"kube-proxy"},{"location":"kubernetes/edx.html#discuss-about-cluster-state-management-with-etcd","text":"Stores cluster state. etcd is distributed Key-Value store based on Raft Concensus Algorithm collection of machines work as group to survive failure of some members. one node will be master, rest followers. Any node can be treated as master. written in Go stores config details: subnets; ConfigMaps; secrets; etc","title":"Discuss about cluster state management with etcd."},{"location":"kubernetes/edx.html#review-the-kubernetes-network-setup-requirements","text":"A unique IP is assigned to each Pod Two Primary Specifications: Container Network Model (CNM) - Docker Container Network Interface (CNI) - CoreOS k8s uses CNI container runtime relies on CNI for IP assignment. CNI connects to underlying configured plugin (Bridge or MACvlan) to get IPs. Plugin passes IPs to CNI which passes IP back to container runtime. Containers in a Pod can communicate to each other The Pod is able to communicate with other Pods in the cluster If configured, the application deployed inside a Pod is accessible from the external world. Container runtime creates isolated network for each container that it starts: network namespace Can be shared across Containers or Host OS. Inside Pod - containers share network namespace - can reach each other via localhost. Pod-to-Pod Communication Across Nodes Pods scheduled on any node. Pods need to communicate across nodes - all nodes should be able to reach any Pod. k8s ideal constraint: No Network Address Translation (NAT) during Pod-to-Pod communication across hosts ^^ Achieved: Routable Pods and nodes - uses underlying physical infrastructure like Google Kubernetes Engine. Software Defined Networking ( Flannel ; Weave ; Calico ; etc) Kubernetes Cluster Networking documentation","title":"Review the Kubernetes network setup requirements."},{"location":"kubernetes/edx.html#ch4-installing-kubernetes","text":"","title":"Ch.4 Installing Kubernetes"},{"location":"kubernetes/edx.html#discuss-about-the-different-kubernetes-configuration-options","text":"","title":"Discuss about the different Kubernetes configuration options."},{"location":"kubernetes/edx.html#all-in-one-single-node-installation","text":"With all-in-one, all the master and worker components are installed on a single node. This is very useful for learning, development, and testing. This type should not be used in production. Minikube is one such example, and we are going to explore it in future chapters.","title":"All-in-One Single-Node Installation"},{"location":"kubernetes/edx.html#single-node-etcd-single-master-and-multi-worker-installation","text":"In this setup, we have a single master node, which also runs a single-node etcd instance. Multiple worker nodes are connected to the master node.","title":"Single-Node etcd, Single-Master, and Multi-Worker Installation"},{"location":"kubernetes/edx.html#single-node-etcd-multi-master-and-multi-worker-installation","text":"In this setup, we have multiple master nodes, which work in an HA mode, but we have a single-node etcd instance. Multiple worker nodes are connected to the master nodes.","title":"Single-Node etcd, Multi-Master, and Multi-Worker Installation"},{"location":"kubernetes/edx.html#multi-node-etcd-multi-master-and-multi-worker-installation","text":"In this mode, etcd is configured in a clustered mode, outside the Kubernetes cluster, and the nodes connect to it. The master nodes are all configured in an HA mode, connecting to multiple worker nodes. This is the most advanced and recommended production setup.","title":"Multi-Node etcd, Multi-Master, and Multi-Worker Installation"},{"location":"kubernetes/edx.html#discuss-infrastructure-considerations-before-installing-kubernetes","text":"Should we set up Kubernetes on bare metal, public cloud, or private cloud? Which underlying system should we use? Should we choose RHEL, CoreOS, CentOS, or something else? Which networking solution should we use? etc Choosing the right solution","title":"Discuss infrastructure considerations before installing Kubernetes."},{"location":"kubernetes/edx.html#discuss-infrastructure-choices-for-a-kubernetes-deployment","text":"","title":"Discuss infrastructure choices for a Kubernetes deployment."},{"location":"kubernetes/edx.html#localhost-installation","text":"Minikube Ubuntu on LXD","title":"Localhost Installation"},{"location":"kubernetes/edx.html#on-premise-installation","text":"On-Premise VMs k8s installed on VMs use Vagrant, VMware vSphere, KVM, etc Automate: Ansible / kubeadm On-Premise Bare Metal on top of OS RHEL, CoreOS, Fedora, Ubuntu, etc","title":"On-Premise Installation"},{"location":"kubernetes/edx.html#cloud-installation","text":"","title":"Cloud Installation"},{"location":"kubernetes/edx.html#hosted-solutions","text":"Google Kubernetes Engine (GKE) Azure Container Service (AKS) Amazon Elastic Container Service for k8s (EKS) - Currently in Tech Preview OpenShift Dedicated Platform9 IBM Cloud Container Service","title":"Hosted Solutions"},{"location":"kubernetes/edx.html#turnkey-cloud-solutions","text":"Google Compute Engine Amazon AWS Microsoft Azure Tectonic by CoreOS","title":"Turnkey Cloud Solutions"},{"location":"kubernetes/edx.html#bare-metal","text":"Various Cloud providers allow Bare Metal installations.","title":"Bare Metal"},{"location":"kubernetes/edx.html#review-kubernetes-installation-tools-and-resources","text":"","title":"Review Kubernetes installation tools and resources."},{"location":"kubernetes/edx.html#kubeadm","text":"first-class citizen in k8s ecosystem. secure/recommended bootstrap of k8s. Contains building blocks to setup cluster. Easily extendable to add functionality. Does not provision machines","title":"kubeadm"},{"location":"kubernetes/edx.html#kubespray","text":"(formerly name: Kargo) Purpose: Install Highly Available k8s cluster on: AWS, GCE, Azure, OpenStack, bare metal. based on Ansible. Available on most Linux distributions. Kubernets Incubator Project","title":"KubeSpray"},{"location":"kubernetes/edx.html#kops","text":"Create/Destroy/Upgrade/Maintain production-grade, HA, k8s clusters from CLI. Can provision machines. AWS officially supported. GCE / VMware vSphere in alpha stage. ++platforms for future. Install k8s from scratch Kubernetes The Hard Way","title":"Kops"},{"location":"kubernetes/edx.html#ch5-setting-up-a-single-node-k8s-cluster-with-minikube","text":"","title":"Ch.5 Setting Up a Single-Node k8s Cluster with Minikube"},{"location":"kubernetes/edx.html#discuss-minikube","text":"runsin VM on Linux/Mac/Windows. Requirements: kubectl binary used to access k8s cluster. Minikube requires kubectl installation to operate, but not to install. On Linux: VirtualBox or KVM hypervisors. On macOS: Hyperkit driver , xhyve driver , VirtualBox , or VMware Fusion hypervisors. On Windows: VirtualBox / Hyper-V hypervisors. VT-x/AMD-v virtualization enabled in BIOS. Internet access on first run.","title":"Discuss Minikube."},{"location":"kubernetes/edx.html#install-minikube-on-linux-mac-and-windows","text":"Start Here: Github Installation directions .","title":"Install Minikube on Linux, Mac, and Windows."},{"location":"kubernetes/edx.html#linux","text":"# Install VirtualBox sudo apt-get install virtualbox # Install Minikube curl -Lo minikube https://storage.googleapis.com/minikube/releases/v0.25.0/minikube-linux-amd64 && chmod +x minikube && sudo mv minikube /usr/local/bin/ # Validate Minikube installation minikube start minikube status minikube stop","title":"Linux"},{"location":"kubernetes/edx.html#mac","text":"Install VirtualBox on macOS # Install Minikube curl -Lo minikube https://storage.googleapis.com/minikube/releases/v0.25.0/minikube-darwin-amd64 && chmod +x minikube && sudo mv minikube /usr/local/bin/ # Validate Minikube installation minikube start minikube status minikube stop","title":"Mac"},{"location":"kubernetes/edx.html#windows","text":"Install VirtualBox Disable Hyper-V Windows support experimental Download the Minikube binary from the Distribution section. Add Minikube binary to $PATH. Set default VM driver for Minikube PS C : \\ Windows \\ system32 > minikube config set vm-driver virtualbox # These changes will take effect upon a minikube delete and then a minikube start Validate Installation PS C : \\ WINDOWS \\ system32 > minikube start PS C : \\ WINDOWS \\ system32 > minikube status PS C : \\ WINDOWS \\ system32 > minikube stop","title":"Windows"},{"location":"kubernetes/edx.html#ch6-accessing-minikube","text":"","title":"Ch.6 Accessing Minikube"},{"location":"kubernetes/edx.html#review-methods-to-access-any-kubernetes-cluster","text":"","title":"Review methods to access any Kubernetes cluster."},{"location":"kubernetes/edx.html#command-line-interface-cli","text":"kubectl","title":"Command Line Interface (CLI)"},{"location":"kubernetes/edx.html#graphical-user-interface-gui","text":"Kubernetes dashboard","title":"Graphical User Interface (GUI)"},{"location":"kubernetes/edx.html#apis","text":"Three independent groups: Core Group (/api/v1) Pods, Services, nodes, etc Named Group objects in /apis/ NAME/ NAME/ VERSION format API versions imply levels of stability/support: Alpha - may be dropped @ any point in time, without notice. Ex: /apis/batch/v2alpha1 Beta - well-tested; semantics of objects may change Ex: /apis/certificates.k8s.io/v1beta1 Stable - appears in released software for many versions Ex: /apis/networking.k8s.io/v1 System-wide system-wide API endpoints Ex: /healthz ; /logs ; /metrcs ; /ui ; etc","title":"APIs."},{"location":"kubernetes/edx.html#configure-kubectl-for-linux-macos-and-windows","text":"","title":"Configure kubectl for Linux, macOS, and Windows."},{"location":"kubernetes/edx.html#linux_1","text":"# Download latest stable kubectl binary curl -LO https://storage.googleapis.com/kubernetes-release/release/ $( curl -s https://storage.googleapis.com/kubernetes-release/release/stable.txt ) /bin/linux/amd64/kubectl # Make kubectl executable chmod +x ./kubectl # Move into PATH sudo mv ./kubectl /usr/local/bin/kubectl","title":"Linux"},{"location":"kubernetes/edx.html#macos","text":"# Download latest stable kubectl binary curl -LO https://storage.googleapis.com/kubernetes-release/release/ $( curl -s https://storage.googleapis.com/kubernetes-release/release/stable.txt ) /bin/darwin/amd64/kubectl # Make kubectl executable chmod +x ./kubectl # Move into PATH sudo mv ./kubectl /usr/local/bin/kubectl OR using Brew: brew install kubectl","title":"macOS"},{"location":"kubernetes/edx.html#windows_1","text":"DL latest kubectl release Depending on latest release, DL kubectl binary # Example download 1.9.3 curl -LO https://storage.googleapis.com/kubernetes-release/release/v1.9.3/bin/windows/amd64/kubectl.exe ` Once downloaded - move kubectl binary to PATH","title":"Windows"},{"location":"kubernetes/edx.html#access-the-minikube-dashboard","text":"minikube dashboard or kubectl proxy - kubectl authenticates with API server on Master node - Makes dashboard available @ http://127.0.0.1:8001/api/v1/namespaces/kube-system/services/kubernetes-dashboard:/proxy/#!/overview?namespace=default - kubernetes-dashboard service runs inside kube-system namespace.","title":"Access the Minikube dashboard."},{"location":"kubernetes/edx.html#access-minikube-via-apis","text":"","title":"Access Minikube via APIs."},{"location":"kubernetes/edx.html#with-kubectl-proxy","text":"kubectl proxy In a new session: curl http://localhost:8001","title":"With kubectl proxy"},{"location":"kubernetes/edx.html#without-kubectl-proxy","text":"Use Bearer Token & kubectl Def: access token generated by authentication server (API server on master node) and given to client # Acquire Token TOKEN = $( kubectl describe secret -n kube-system $( kubectl get secrets -n kube-system | grep default | cut -f1 -d ' ' ) | grep -E '^token' | cut -f2 -d ':' | tr -d '\\t' | tr -d \" \" ) # Retrieve API server endpoint APISERVER = $( kubectl config view | grep https | cut -f 2 - -d \":\" | tr -d \" \" ) # Access API Server using curl curl $APISERVER --header \"Authorization: Bearer $TOKEN \" --insecure","title":"Without kubectl proxy"},{"location":"kubernetes/edx.html#ch7-kubernetes-building-blocks","text":"","title":"Ch.7 Kubernetes Building Blocks"},{"location":"kubernetes/edx.html#review-the-kubernetes-object-model","text":"Object Model: what containerized apps are running on each node app resource consumption Policies attached to app (restart/upgrade, fault tolerance, etc) For each Object: dcl desired state using spec field. k8s manages status field for objects - state of object. k8s Control Plane always attempting to match desired state with actual state. Ex Objects: Pods, ReplicaSets, Deployments, Namespaces, etc To create Objects: Provide spec field to k8s API server. spec describes desired state & basic info (name, etc) JSON format usually define object's definition in .yaml file kubectl converts to JSON payload and sends to API server. TODO(Wes): Reduce > With the apiVersion field in the example above, we mention the API endpoint on the API server which we want to connect to. With the kind field, we mention the object type - in our case, we have Deployment. With the metadata field, we attach the basic information to objects, like the name. You may have noticed that in our example we have two spec fields (spec and spec.template.spec). With spec, we define the desired state of the deployment. In our example, we want to make sure that, at any point in time, at least 3 Pods are running, which are created using the Pods Template defined in spec.template. In spec.template.spec, we define the desired state of the Pod. Here, our Pod would be created using nginx:1.7.9.","title":"Review the Kubernetes object model."},{"location":"kubernetes/edx.html#discuss-labels-and-selectors","text":"Labels key-value pairs attached to k8s objects (e.g. Pods). organize & subset objects many objects -to- one label labels != unique to object Above Labels: app / env Label Selectors Equality-Based filter objects on Label keys and values = , == , != operators Ex: env==dev Set-Based filter objects on set of values in , notin , exists operators Ex: env in (dev, qa)","title":"Discuss Labels and Selectors."},{"location":"kubernetes/edx.html#discuss-kubernetes-building-blocks","text":"","title":"Discuss Kubernetes building blocks"},{"location":"kubernetes/edx.html#pods","text":"smallest k8s object. unit of deployment in k8s represents single instance of the app Pod is logical collection of 1+ containers, which: Are scheduled together on the same host Share the same network namespace Mount the same external storage (volumes). Ephemeral; can not self-heal use with controllers handle Pod's replication, fault tolerance, self-heal, etc Controller Ex: Deployments, ReplicaSets, ReplicationControllers, etc Pod Templates attach Pod's specificiation to other objects","title":"Pods"},{"location":"kubernetes/edx.html#replicationcontroller-rc","text":"part of master node's controller manager. assures specified # replicas for Pod are running. controllers like rc always used to create/manage Pods. only supports equality-based Selectors.","title":"ReplicationController (rc)"},{"location":"kubernetes/edx.html#replicasets","text":"next generation ReplicationController support both equality- and set-based selectors One Pod dies, current state != desired state ReplicaSet detects; creates Pod ReplicaSets can be independent; mostly used by Deployments to orchestrate Pod creation, deletion, updates.","title":"ReplicaSets"},{"location":"kubernetes/edx.html#deployments","text":"object automatically creates ReplicaSets. provides declarative updates to Pods and ReplicaSets. DeploymentController part of master node's controller manager. assures curret state == desired state. feature: Deployment recording (deployments explained below) if something goes wrong - rollback to previous state Below graphic: Deployment creates ReplicaSet A . ReplicaSet A creates 3 Pods . Each Pod - one container uses nginx:1.7.9 . Next graphic: in Deployment we change Pods Template & update image for nginx container to nginx:1.9.1 . Pod Template modified: new ReplicaSet B created. process referred to as Deployment rollout . rollout only triggered on Pods Template update for deployment. Scaling operations do not trigger deployment. Next graphic: When ReplicaSet B ready: Deployment points to it.","title":"Deployments"},{"location":"kubernetes/edx.html#namespaces","text":"partitions k8s cluster. Ex: numerous users - organize into teams/projects. names of resources/objects created in Namespace are unique, but not across Namespaces . List all Namespaces : $ kubectl get namespaces NAME STATUS AGE default Active 11h kube-public Active 11h kube-system Active 11h k8s creates 2 default Namespaces: kube-system objects created by k8s system. default objects from any other Namespace. by default, we connect to default Namespace. kube-public readable by all users. used for special purposes (Ex: bootstrapping a cluster). Resource Quotas divide cluster resources within Namespaces.","title":"Namespaces"},{"location":"kubernetes/edx.html#ch8-authentication-authorization-admission-control","text":"Objective: Discuss authentication, authorization, and access control stages of the Kubernetes API access. Understand the different kinds of Kubernetes users. Discuss the different modules for authentication and authorization.","title":"Ch.8 Authentication, Authorization, Admission Control"},{"location":"kubernetes/edx.html#stages-of-k8s-api-access","text":"","title":"Stages of k8s API access"},{"location":"kubernetes/edx.html#authentication","text":"Logs in user. k8s does not have object user , or store usernames . k8s can use usernames for access control and request logging. Two kinds of users: Normal Users Managed outside k8s cluster via independent services, Ex: User/Client Certificates file listing usernames/passwords Google accounts etc Service Accounts in-cluster processes communicate with API server to perform operations. Most Service Account users auto-created via API server Can also create manually Service Account users tied to given Namespace mounts respective credentials to communicate with API server as Secrets.","title":"Authentication"},{"location":"kubernetes/edx.html#authentication-modules","text":"Overview: Multiple authenticators can be enabled first module to successfully authenticate request short-circuits the evaluation. to be successful - enable at least 2 methods: service account tokens authenticator user authenticator k8s also supports anonymous requests , if configured Client Certificates enable w/reference to file w/1+ cert authorities pass --client-ca-file=SOMEFILE option to API server. cert auths in file validate client certs presented to API server. Demo Video: Static Token File pass file w/pre-defined bearer tokens pass with --token-auth-file=SOMEFILE option to API server. these tokens last indefinitely. cannot change w/o restarting API server Bootstrap Tokens alpha; used in bootstrapping new k8s cluster. Static Password File pass file w/basic authentication details pass w/ --basic-auth-file=SOMEFILE option to API server. lasts indefinitely change w/API server restart Service Account Tokens auto-enabled authenticator uses signed bearer tokens to verify requests tokens attached to Pods using ServiceAccount Admission Controller . allows in-cluster processes to talk to API server. OpenID Connect Tokens connect with OAuth 2 providers Ex: Azure Active Directory, Salesforce, Google, etc Webhook Token Authentication verification of bearer tokens offloaded to remote servce. Keystone Password pass --experimental-keystone-url=<AuthURL> option to API Server. AuthURL is Keystone server endpoint. Authenticating Proxy used to program additional authentication logic","title":"Authentication Modules"},{"location":"kubernetes/edx.html#authorization","text":"Authorizes API requests. After Authentication, users send API requests to perform operations. API requests are Authorized API request attributes authorized: user, group extra, Resource, Namespace, etc these attributes evaluated against policies. if evalualtion success - request allowed; otherwise denied. Multiple Authorization modules/authorizers. 1+ module can be configured for k8s cluster each module checked in sequence if any authorizer approves/denies - that decision is returned immediately.","title":"Authorization"},{"location":"kubernetes/edx.html#authorization-modules","text":"Node Authorizer authorizes API requests from kubelets authorizes kubelet's: read operations for services, endpoints, nodes, etc write operators for nodes, pods, events, etc Kubernetes documentation Attribute-Based Access Control (ABAC) Authorizer k8s grants access to API requests - combine policies with attributes. Ex: user nkhare can only read Pods in Namespace lfs158 : { \"apiVersion\" : \"abac.authorization.kubernetes.io/v1beta1\" , \"kind\" : \"Policy\" , \"spec\" : { \"user\" : \"nkhare\" , \"namespace\" : \"lfs158\" , \"resource\" : \"pods\" , \"readonly\" : true } } enable w/ --authorization-mode=ABAC option to API server. specify authorization policy: --authorization-policy-file=PolicyFile.json Kubernetes documentation Webhook Authorizer k8s offers authorization decisions to 3 rd -party services enable: --authorization-webhook-config-file=SOME_FILENAME SOME_FILENAME: config of remote authorization service Kubernetes documentation Role-Based Access Control (RBAC) Authorizer regulate access to resources based on user assigned roles roles: users, service accounts, etc enable: --authorization-mode=RBAC to API server. Kubernetes documentation roles assigned operations: create , get , update , patch , etc operations known as \"verbs\" Two kids of roles: Role grant access to resource within specific Namespace kind: Role apiVersion: rbac.authorization.k8s.io/v1 metadata: namespace: lfs158 name: pod-reader rules: - apiGroups: [ \"\" ] # \"\" indicates the core API group resources: [ \"pods\" ] verbs: [ \"get\" , \"watch\" , \"list\" ] creates pod-reader role access only to Pods of lfs158 Namespace. ClusterRole grany access to resource with cluster-wide scope Once Role is created - bind users with RoleBinding RoleBinding bind users to same namespace as a Role. kind: RoleBinding apiVersion: rbac.authorization.k8s.io/v1 metadata: name: pod-read-access namespace: lfs158 subjects: - kind: User name: nkhare apiGroup: rbac.authorization.k8s.io roleRef: kind: Role name: pod-reader apiGroup: rbac.authorization.k8s.io user nkhare access to read Pods of lfs158 Namespace. ClusterRoleBinding grant access to resources @ cluster-level and to all Namespaces.","title":"Authorization Modules"},{"location":"kubernetes/edx.html#admission-control","text":"Modules which modify/reject requests based on additional checks: Ex: Quota Granular access control policies allowing privledged containers, checking resource quota, etc Resource Controllers: ResourceQuota, AlwaysAdmit, DefaultStorageClass, etc in effect only after API requests authenticated/authorized enable admission controls: start k8s API server w/ admission-control takes comma-delimited, ordered list of controller names --admission-control=NamespaceLifecyl,ResourceQuota,PodSecurityPolicy,DefaultStorageClass Kubernetes documentation","title":"Admission Control"},{"location":"kubernetes/edx.html#ch9-services","text":"","title":"Ch.9 Services"},{"location":"kubernetes/edx.html#objective","text":"Discuss the benefits of grouping Pods into Services to access an application. Explain the role of the kube-proxy daemon running on each worker node. Explore the Service discovery options available in Kubernetes. Discuss different Service types.","title":"Objective:"},{"location":"kubernetes/edx.html#connecting-users-to-pods","text":"IP's assigned dynamically - Pods are ephemeral. User/Client connected Pod dies - new Pod created. New Pod - New IP. k8s provides Services higher level abstraction than IP. groups Pods and policy to access them. grouping via Labels and Selectors .","title":"Connecting Users to Pods"},{"location":"kubernetes/edx.html#services","text":"app keyword as Label. frontend & db values for Pods Selectors ( app==frontend & app==db ) groups into 2 logical groups: 1 w/3 Pods 1 w/1 Pod assign name to logical grouping: Service name . Ex: Two Services: frontend-svc selector: app==frontend db-svc selector: app==db","title":"Services"},{"location":"kubernetes/edx.html#service-object-example","text":"kind: Service apiVersion: v1 metadata: name: frontend-svc spec: selector: app: frontend ports: - protocol: TCP port: 80 targetPort: 5000 Explain: Service: frontend-svc Selects Pods w/Label app==frontend Each Service receives IP address by default routable only inside cluster In Example: 172.17.0.4 for frontend-svc Service 172.17.0.5 for db-svc Service IP address attached to Service known as ClusterIP for that Service. User/Client connects to service via IP. Service forwards traffic to one of attached Pods. Service load balances while selecting the Pods for forwarding. can select Port to forward Ex: frontend-svc receives requests from user/client on Port 80 . frontend-svc forwards to Pod on Port 5000 . If no port designated: Service forwards on same port received Service endpoint tuple of Pods, IP, targetPort Ex: frontend-svc has 3 endpoints: 10.0.1.3:5000 10.0.1.4:5000 10.0.1.5:5000","title":"Service Object Example"},{"location":"kubernetes/edx.html#kube-proxy_1","text":"worker nodes run daemon called kube-proxy watches API server on master node for addition/removal of Services/endpoints. For each new Service, on each node, kube-proxy configures iptables to capture traffic for its ClusterIP & forwards to one of the endpoints. When Service removed: kube-proxy removes iptables rules on all nodes as well.","title":"kube-proxy"},{"location":"kubernetes/edx.html#service-discovery","text":"Two methods for discovering Services: Environment Variables @Pod Start, kubelet daemon on node adds env variables in Pod for all active Services. Ex: Service: redis-master ; exposes port 6379 ClusterIP 172.17.0.6 then, new Pod: REDIS_MASTER_SERVICE_HOST = 172 .17.0.6 REDIS_MASTER_SERVICE_PORT = 6379 REDIS_MASTER_PORT = tcp://172.17.0.6:6379 REDIS_MASTER_PORT_6379_TCP = tcp://172.17.0.6:6379 REDIS_MASTER_PORT_6379_TCP_PROTO = tcp REDIS_MASTER_PORT_6379_TCP_PORT = 6379 REDIS_MASTER_PORT_6379_TCP_ADDR = 172 .17.0.6 Note : Pods will not have env variables for Services created after Pod creation. DNS most common; recommended. addon for DNS . creates DNS record for each Service format: my-svc.my-namespace.svc.cluster.local Services w/same Namespace can talk. Ex: Service: redis-master in my-ns Namespace. All Pods in same Namespace can reach redis Service by using its name: redis-master Pods from other Namespaces can reach redis-master Service, by: Add respective Namespace as suffix: redis-master.my-ns .","title":"Service Discovery"},{"location":"kubernetes/edx.html#servicetype","text":"Access scope decided by ServiceType - can be mentioned when creating Service. Is the Service: only accessible within the cluster? accessible from within the cluster and the external world? Maps to an external entity which resides outside the cluster?","title":"ServiceType"},{"location":"kubernetes/edx.html#clusterip","text":"default ServiceType Service receives Virtual IP using ClusterIP. assigned IP used for communicating w/Service accessible only within Cluster.","title":"ClusterIP"},{"location":"kubernetes/edx.html#nodeport","text":"in addition to creating ClusterIP: port range 30000-32767 mapped to respective Service, from all worker nodes. Ex: mapped NodePort: 32233 for service frontend-svc connect to any worker node on 32233 node redirects all traffic to ClusterIP - 172.17.0.4 Default: when expose NodePort => random port auto-selected by k8s Master from range 30000-32767 . can assign specific port to avoid dynamic port value while creating service. NodePort ServiceType can make Services accessible to external world. end-user connects to worker nodes on specified port worker node forwards traffic to apps running inside cluster. admins can configure reverse proxy outside k8s cluster map specific endpoint to respective port on worker nodes","title":"NodePort"},{"location":"kubernetes/edx.html#loadbalancer","text":"NodePort & ClusterIP Services automatically created external load balancer will route to them Services exposed @ static port on each worker node Service exposed externally w/underlying cloud provider's load balance feature. LoadBalancer ServiceType only works if: underlying IaaS supports automatic creation of Load Balancers and support in k8s (GCP/AWS)","title":"LoadBalancer"},{"location":"kubernetes/edx.html#externalip","text":"Service mapped to ExternalIP if it can route to one or more worker nodes. Traffic ingressed with ExternalIP (as destination IP) on Service port is routed to one of the Service endpoints. Note: ExternalIPs not managed by k8s. cluster admins configure routing to map ExternalIP address to one of the nodes.","title":"ExternalIP"},{"location":"kubernetes/edx.html#externalname","text":"ExternalName special ServiceType no Selectors does not define any endpoints when accessed within cluster: returns CNAME record of externally configured Service. make externally configured Services ( my-database.example.com ) available inside cluster requires just the name (like, my-database ) available inside same Namespace","title":"ExternalName"},{"location":"kubernetes/edx.html#ch10-deploying-a-stand-alone-application","text":"Objective: Deploy an application from the dashboard. Deploy an application from a YAML file using kubectl. Expose a service using NodePort. Access the application from the external world.","title":"Ch.10 Deploying a Stand-Alone Application"},{"location":"kubernetes/edx.html#minikube-gui","text":"minikube start minikube status minikube dashboard Deploy webserver usign nginx:alpine image: Dashboard: click: CREATE Tab: CREATE AN APP Enter as seen: Click: DEPLOY","title":"Minikube GUI"},{"location":"kubernetes/edx.html#kubectl-cli","text":"kubectl get deployments kubectl get replicasets kubectl get pods","title":"kubectl CLI"},{"location":"kubernetes/edx.html#labels-selectors","text":"kubectl describe pod webserver-74d8bd488f-xxxxx kubectl get pods -L k8s-app,label2 # -L option = add additional columns in output kubectl get pods -l k8s-app = webserver # -l option = selector","title":"Labels / Selectors"},{"location":"kubernetes/edx.html#delete-deployment","text":"kubectl delete deployments webserver # Also deletes ReplicaSets & Pods","title":"Delete Deployment"},{"location":"kubernetes/edx.html#deployment-yaml","text":"Create webserver.yaml # webserver.yaml apiVersion: apps/v1 kind: Deployment metadata: name: webserver labels: app: nginx spec: replicas: 3 selector: matchLabels: app: nginx template: metadata: labels: app: nginx spec: containers: - name: nginx image: nginx:alpine ports: - containerPort: 80 kubectl create -f webserver.yaml","title":"Deployment YAML"},{"location":"kubernetes/edx.html#create-expose-wnodeport","text":"ServiceTypes : define access method for given Service. With NodePort ServiceType k8s opens static port on all worker nodes. Connect to open static port from any node - forwarded to respective Service. Create webserver-svc.yaml : # webserver-svc.yaml apiVersion: v1 kind: Service metadata: name: web-service labels: run: web-service spec: type: NodePort ports: - port: 80 protocol: TCP selector: app: nginx kubectl create -f webserver-svc.yaml kubectl get svc NAME TYPE CLUSTER-IP EXTERNAL-IP PORT ( S ) AGE kubernetes ClusterIP 10 .96.0.1 <none> 443 /TCP 4d web-service NodePort 10 .108.132.106 <none> 80 :31791/TCP 3m ClusterIP: 10.108.132.106 Port: 80:31791 We've reserved static port 31791 on node. If connect to node on that port - request forwarded to ClusterIP on port 80. Deployment / Service creation can happen in any order. kubectl describe svc web-service web-service uses app=nginx as Selector, which selects the three Pods - listed as endpoints. So, whenever a request is sent to our Service - served by one of Pods listed in Endpoints section.","title":"Create / Expose w/NodePort"},{"location":"kubernetes/edx.html#access-app-using-exposed-nodeport","text":"minikube ip Open browser @ listed IP and kubectl describe svc web-service NodePort. or , at CLI: minikube service web-service","title":"Access App Using Exposed NodePort"},{"location":"kubernetes/edx.html#liveness-readiness-probes","text":"Kubernetes documentation Liveness Probe checks application health if fails - restarts container Set by Defining: Liveness Command Liveness HTTP request TCP Liveness Probe","title":"Liveness / Readiness Probes"},{"location":"kubernetes/edx.html#liveness-command","text":"Check existence of file /tmp/healthy : # liveness-exec.yaml apiVersion: v1 kind: Pod metadata: labels: test: liveness name: liveness-exec spec: containers: - name: liveness image: k8s.gcr.io/busybox args: - /bin/sh - -c - touch /tmp/healthy; sleep 30; rm -rf /tmp/healthy; sleep 600 livenessProbe: exec: command: - cat - /tmp/healthy initialDelaySeconds: 3 periodSeconds: 5 kubectl create -f liveness-exec.yaml kubectl get pods kubectl describe pod liveness-exec - periodSeconds: tmp/healthy checked every 5 seconds. - initialDelaySeconds: requests kubelet to wait 3 seoncds before first probe.","title":"Liveness Command"},{"location":"kubernetes/edx.html#liveness-http-request","text":"kubelet sends HTTP GET request to /healthz endpoint of application on port 8080. # liveness-http.yaml apiVersion: v1 kind: Pod metadata: labels: test: liveness name: liveness-exec spec: containers: - name: liveness image: k8s.gcr.io/busybox args: - /bin/sh - -c - touch /tmp/healthy ; sleep 30 ; rm -rf /tmp/healthy ; sleep 600 livenessProbe: httpGet: path: /healthz port: 8080 httpHeaders: - name: X-Custom-Header value: Awesome initialDelaySeconds: 3 periodSeconds: 3","title":"Liveness HTTP Request"},{"location":"kubernetes/edx.html#tcp-liveness-probe","text":"kubelet attempts to open TCP socket to the container running application. # liveness-tcp.yaml apiVersion: v1 kind: Pod metadata: labels: test: liveness name: liveness-exec spec: containers: - name: liveness image: k8s.gcr.io/busybox args: - /bin/sh - -c - touch /tmp/healthy ; sleep 30 ; rm -rf /tmp/healthy ; sleep 600 livenessProbe: tcpSocket: port: 8080 initialDelaySeconds: 15 periodSeconds: 20","title":"TCP Liveness Probe"},{"location":"kubernetes/edx.html#readiness-probes","text":"Application must meet conditions before receiving traffic. # readiness-probe.yaml apiVersion: v1 kind: Pod metadata: labels: test: readiness name: readiness-exec spec: containers: - name: readiness image: k8s.gcr.io/busybox args: - /bin/sh - -c - sleep 20 ; touch /tmp/healthy ; sleep 20 ; rm -rf /tmp/healthy ; sleep 600 readinessProbe: exec: command: - cat - /tmp/healthy initialDelaySeconds: 5 periodSeconds: 5","title":"Readiness Probes"},{"location":"kubernetes/edx.html#ch11-kubernetes-volume-management","text":"Explain the need for persistent data management. Discuss Kubernetes Volume and its types. Discuss PersistentVolumes and PersistentVolumeClaims.","title":"Ch.11 Kubernetes Volume Management"},{"location":"kubernetes/edx.html#volumes","text":"Containers, and their data, are ephemeral. Solve with Volumes. Volume attached to a Pod, shared among containers in Pod. Volume has same life span as Pod. Outlives containers of Pod. Data preserved across container restart.","title":"Volumes"},{"location":"kubernetes/edx.html#volume-types","text":"Directory mounted in Pod backed by underlying Volume Type - decides properties of directory (size, content, etc). emptyDir empty Volume created for Pod as soon as it's scheduled on worker node. Volume life coupled with Pod. Pod dies - content of emptyDir deleted. hostPath share a directory from the host to Pod. Pod dies - content of Volume available on host. gcePersistentDisk mount Google Compute Engine (GCE) persistent disk into Pod. awsElasticBlockStore mount AWS EBS Volume into Pod. nfs mount NFS share into Pod. iscsi mount iSCSI share into Pod. secret pass sensitive information (passwords) to Pods. persistentVolumeClaim attach PersistentVolume to Pod. Kubernetes Volume Types","title":"Volume Types"},{"location":"kubernetes/edx.html#persistent-volumes","text":"Network-attached storage in the cluster - provisioned by admin. PersistentVolume (PV) subsystem provides APIs for users/admins to manage / consume storage. Manage: PersistentVolume API resource type. Consume: PersistentVolumeClaim API resource type. PersistentVolumes can be dynamically provisioned based on StorageClass resource. StorageClass contains pre-defined provisioners and parameters to create a PersistentVolume. Using PersistentVolumeClaims: User sends request for dynamic PV creation. wired to StorageClass resource. Volume Types that support managing using PersistentVolumes: GCEPersistentDisk AWSElasticBlockStore AzureFile NFS iSCSI Complete List: Kubernetes Documentation","title":"Persistent Volumes"},{"location":"kubernetes/edx.html#persistentvolumeclaims","text":"PersistentVolumeClaim (PVC) is user request for storage. User requests for PersistentVolume resources based on size, access models, etc. Once suitable PersistentVolume is found: bound to a PersistentVolumeClaim. After successful bound, PersistentVolumeClaim resource can be used in Pod. When finished - attached PersistentVolumes can be released, reclaimed, recycled. See Kubernetes Documentation .","title":"PersistentVolumeClaims"},{"location":"kubernetes/edx.html#container-storage-interface-csi","text":"Container orchestrators (k8s, Mesos, Docker, etc) each have unqiue method of managing external storage using Volumes. Storage Vendors can't keep up with differences. Let's standardize! Container Storage Interface specifications .","title":"Container Storage Interface (CSI)"},{"location":"kubernetes/edx.html#ch12-deploying-a-multi-tier-application","text":"Analyze a sample multi-tier application. Deploy a multi-tier application. Scale an application.","title":"Ch.12 Deploying a Multi-Tier Application"},{"location":"kubernetes/edx.html#rsvp-application","text":"users register for event. provide username/email. name/email goes in table. App: backend database: MongoDB frontend: Python Flask-based Code: github - rsvp.py - look for MONGODB_HOST env variable for db endpoint. - connect to it on port 27017 MONGODB_HOST = os.environ.get ( 'MONGODB_HOST' , 'localhost' ) client = MongoCLient ( MONGODB_HOST, 27017 ) Deploy with 1 backend / 1 frontend then, scale","title":"RSVP Application"},{"location":"kubernetes/edx.html#backend","text":"# rsvp-db.yaml apiVersion: apps/v1 kind: Deployment metadata: name: rsvp-db labels: appdb: rsvpdb spec: replicas: 1 selector: matchLabels: appdb: rsvpdb template: metadata: labels: appdb: rsvpdb spec: containers: - name: rsvp-db image: mongo:3.3 ports: - containerPort: 27017 kubectl create -f rsvp-db.yaml Create mongodb service. # rsvp-db-service.yaml apiVersion: v1 kind: Service metadata: name: mongodb labels: app: rsvpdb spec: ports: - port: 27017 protocol: TCP selector: appdb: rsvpdb kubectl create -f rsvp-db-service.yaml did not specify ServiceType mongodb has default ClusterIP ServiceType . mongodb will not be accessible from external world. kubectl get deployments kubectl get services","title":"Backend"},{"location":"kubernetes/edx.html#frontend","text":"using Python Flask-based microframework source: https://raw.githubusercontent.com/cloudyuga/rsvpapp/master/rsvp.py Docker image: teamcloudyuga/rsvpapp Dockerfile to create teamcloudyuga/rsvpapp: https://raw.githubusercontent.com/cloudyuga/rsvpapp/master/Dockerfile Create Deployment for rsvp Frontend. # rsvp-web.yaml apiVersion: apps/v1 kind: Deployment metadata: name: rsvp labels: app: rsvp spec: replicas: 1 selector: matchLabels: app: rsvp template: metadata: labels: app: rsvp spec: containers: - name: rsvp-app image: teamcloudyuga/rsvpapp env: - name: MONGODB_HOST value: mongodb ports: - containerPort: 5000 name: web-port kubectl create -f rsvp-web.yaml passing name of MongoDB Service, mongodb , as env variable. expected by frontend Note Ports: containerPort 5000 name: web-port Can change underlying containerPort without making changes Service. Create Service for rsvp Frontend. # rsvp-web-service.yaml apiVersion: v1 kind: Service metadata: name: rsvp labels: app: rsvp spec: type: NodePort ports: - port: 80 targetPort: web-port protocol: TCP selector: app: rsvp kubectl create -f rsvp-web-service.yaml Note: targetPort in ports section. forwards requests on port 80 for ClusterIP to web-port port (5000) on connected Pods. Look @ available deployments and services: kubectl get deployments kubectl get services","title":"Frontend"},{"location":"kubernetes/edx.html#access-rsvp-application","text":"minikube ip # NodePort Port kubectl get services OR minikube service rsvp","title":"Access RSVP Application"},{"location":"kubernetes/edx.html#scale-frontend","text":"Scale from 1 to 4 replicas: kubectl scale deployment rsvp --replicas = 3 kubectl get deployments Refreshing site will show multiple Host: rsvp-xxx-xxx as routed to different endpoints.","title":"Scale Frontend"},{"location":"kubernetes/edx.html#ch13-configmaps-and-secrets","text":"Discuss configuration management for applications in Kubernetes using ConfigMaps. Share sensitive data (such as passwords) using Secrets.","title":"Ch.13 ConfigMaps and Secrets"},{"location":"kubernetes/edx.html#configmaps","text":"decouples config details from container image. pass as key-value pairs later consumed by Pods, controllers, other system components, etc. Create by: literal value files","title":"ConfigMaps"},{"location":"kubernetes/edx.html#create-configmap-cli","text":"kubectl create configmap my-config --from-literal = key1 = value1 --from-literal = key2 = value2","title":"Create ConfigMap @ CLI"},{"location":"kubernetes/edx.html#get-configmap-details","text":"kubectl get configmaps my-config -o yaml","title":"Get ConfigMap Details"},{"location":"kubernetes/edx.html#create-configmap-from-file","text":"# customer1-configmap.yaml apiVersion: v1 kind: ConfigMap metadata: name: customer1 data: TEXT1: Customer1_Company TEXT2: Welcomes You COMPANY: Customer1 Company Technology Pct. Ltd. kubectl create -f customer1-configmap.yaml","title":"Create ConfigMap from file."},{"location":"kubernetes/edx.html#use-configmap-in-pods","text":"While creating deployment - assign values for env variables from customer1 ConfigMap: # container .... containers: - name: rsvp-app image: teamcloudyuga/rsvpapp env: - name: MONGODB_HOST value: mongodb - name: TEXT1 valueFrom: configMapKeyRef: name: customer1 key: TEXT1 - name: TEXT2 valueFrom: configMapKeyRef: name: customer1 key: TEXT2 - name: COMPANY valueFrom: configMapKeyRef: name: customer1 key: COMPANY .... TEXT1 env var: \"Customer1_Company\" TEXT2 env var: \"Welcomes You\"","title":"Use ConfigMap in Pods"},{"location":"kubernetes/edx.html#mount-configmap-as-volume","text":"Kubernetes documentation on ConfigMaps . For Each key: file in mount path is key content of file becomes value","title":"Mount ConfigMap as Volume"},{"location":"kubernetes/edx.html#secrets","text":"Shares sensitive info (pws, tokens, keys) passed as key-value pairs Secret objects are referenced in Deployments. Secret data stored as plain text inside etcd . kubectl create secret generic my-password --from-literal = password = my3q1p@ssw0rd kubectl get secret my-password kubectl describe secret my-password","title":"Secrets"},{"location":"kubernetes/edx.html#create-secret-manually","text":"With Secrets, each object must be encoded using base64. echo mysqlpassword | base64 Use base64 encoded password in config file: # my-password.yaml apiVersion: v1 kind: Secret metadata: name: my-password type: Opaque data: password: bXlzcWxwYXNzd29yZAo = base64 != encryption: echo \"bXlzcWxwYXNzd29yZAo=\" | base64 --decode","title":"Create Secret Manually"},{"location":"kubernetes/edx.html#use-secrets-inside-pods","text":"expose as env variable or mount as data volume","title":"Use Secrets Inside Pods"},{"location":"kubernetes/edx.html#environment-variable","text":"Reference a Secret & assign value of its key as env variable WORDPRESS_DB_PASSWORD : ..... spec: containers: - image: wordpress:4.7.3-apache name: wordpress env: - name: WORDPRESS_DB_HOST value: wordpress-mysql - name: WORDPRESS_DB_PASSWORD valueFrom: secretKeyRef: name: my-password key: password .....","title":"Environment Variable"},{"location":"kubernetes/edx.html#mount-as-volume","text":"Secrets as Files from Pod: mount Secret as Volume inside Pod. file created for each key in Secret contents = value Kubernetes documentation","title":"Mount as Volume"},{"location":"kubernetes/edx.html#ch14-ingress","text":"Objective: Explain what Ingress and Ingress Controllers are. Learn when to use Ingress. Access an application from the external world using Ingress. Ingress allows updates to app w/o worrying about external access. \"An Ingress is a collection of rules that allow inbound connections to reach the cluster Services.\" Ingress configures Layer 7 HTTP load balancer for Services. Provides: TLS (Transport Layer Security) Name-based virtual hosting Path-based routing Custom roles Users don't connect directly to Service. Users reach Ingress endpoint, forwarded to respective Service. # webserver-ingress.yaml apiVersion: extensions/v1beta1 kind: Ingress metadata: name: web-ingress namespace: default spec: rules: - host: blue.example.com http: paths: - backend: serviceName: webserver-blue-svc servicePort: 80 - host: green.example.com http: paths: - backend: serviceName: webserver-green-svc servicePort: 80 Above, Example of Name-Based Virtual Hosting Ingress rule: User requests to both blue.example.com & green.example.com routed to same Ingress endpoint. forwarded to webserver-blue-svc & webserver-green-svn , respectively. Below, Example of Fan Out Ingress rules: requests: example.com/blue & example.com/green forwarded: webserver-blue-svc & webserver-green-svc , respectively.","title":"Ch.14 Ingress"},{"location":"kubernetes/edx.html#ingress-controller","text":"Ingress Controller watches Master Node's API server for changes in Ingress resources updates Layer 7 Load Balancer accordingly. k8s has several Ingress Controllers: GCE L7 Load Balancer Nginx Ingress Controller can also build your own","title":"Ingress Controller"},{"location":"kubernetes/edx.html#start-ingress-controller-wminikube","text":"Minikube v0.14.0+ contains Nginx Ingress Controller setup as addon: minikube addons enable ingress","title":"Start Ingress Controller w/Minikube"},{"location":"kubernetes/edx.html#deploy-ingress-resource","text":"# webserver-ingress.yaml apiVersion: extensions/v1beta1 kind: Ingress metadata: name: web-ingress namespace: default spec: rules: - host: blue.example.com http: paths: - backend: serviceName: webserver-blue-svc servicePort: 80 - host: green.example.com http: paths: - backend: serviceName: webserver-green-svc servicePort: 80 kubectl create -f webserver-ingress.yaml","title":"Deploy Ingress Resource"},{"location":"kubernetes/edx.html#access-services-using-ingress","text":"Should now have access to: webserver-blue-svc & webserver-green-svc via blue.example.com & green.example.com Setup on Minikube (local VM), update host config file ( /etc/hosts on Mac/Linux): minikube ip 192 .168.99.100 cat /etc/hosts 127 .0.0.1 localhost ::1 localhost 192 .168.99.100 blue.example.com green.example.com","title":"Access Services Using Ingress"},{"location":"kubernetes/edx.html#ch15-advanced-topics","text":"","title":"Ch.15 Advanced Topics"},{"location":"kubernetes/edx.html#annotations","text":"Attach arbitrary non-identifying metadata to any objects, K-V \"annotations\" : { \"key1\" : \"value1\" , \"key2\" : \"value2\" } Not used to ID/select objects, instead: Store buid/release IDs, PR numbers, git branch ,etc Phone/pager numbers of people responsible, directory entries specifying where that info can be found Pointers to logging, monitoring, analytics, audit repositories, debugging tools, etc. Etc Ex: While Create Deployment, add description like: apiVersion : extensions/v1beta1 kind : Deployment metadata : name : webserver annotations : description : Deployment based PoC dates 2nd June'2017 .... Look @ annotations while describing object: kubectl describe deployment webserver Name: webserver Namespace: default CreationTimestamp: Sat, 03 Jun 2017 05 :10:38 +0530 Labels: app = webserver Annotations: deployment.kubernetes.io/revision = 1 description = Deployment based PoC dates 2nd June ' 2017 ...","title":"Annotations"},{"location":"kubernetes/edx.html#deployment-features","text":"Record Deployment, revert if wrecks. If recorded Deployment before update, revert back to known working state: Deployment Object also provides: Autoscaling Proportional scaling Pausing and resuming.","title":"Deployment Features"},{"location":"kubernetes/edx.html#jobs","text":"Creates 1+ Pods to perform task. Job object takes responsibility of Pod failures. Assures task completed successfully. Task complete - Pods terminate automatically. Can be scheduled for times/dates. CronJob","title":"Jobs"},{"location":"kubernetes/edx.html#quota-management","text":"ResourceQuota object. Provides contraints that limit aggregate resource consumption per Namespace. Types of Quotas per Namespace: Compute Resource Quota limit total sum of compute resources (CPU, memory, etc) which can be requested in Namespace. Storage Resource Quota Limit sum of storage resources (PersistentVolumeClaims, requests.storage, etc). Object Count Quota Restrict # objects of given type (Pods, ConfigMaps, PersistentVolumeClaims, ReplicationControllers, Services, Secrets, etc).","title":"Quota Management"},{"location":"kubernetes/edx.html#daemonsets","text":"DaemonSet object allows: collecting monitoring data from all nodes. running storage daemon on all nodes. etc. specific type of Pod running on all nodes at all times. When Node added to Cluster: Pod from given DaemonSet created on it. When Node dies Respective Pods garbage collected. If DaemonSet deleted - all Pods it created are deleted as well.","title":"DaemonSets"},{"location":"kubernetes/edx.html#statefulsets","text":"StatefulSet controller used for apps requiring unique identity: name network identifications strict ordering etc, Ex: MySQL cluster , etcd cluster Provides ID and guaranteed ordering of deployment and scaling of Pods.","title":"StatefulSets"},{"location":"kubernetes/edx.html#kubernetes-cluster-federation","text":"Manage multiple k8s clusters from single control plane. Sync resources across clusters & cross-cluster discovery. Allows Deployments across regions, and access using global DNS record. Useful w/hybrid solutions: Cluster inside private datacenter. and Cluster on public cloud. Can assign weights for each cluster in the Federation - distribute load.","title":"Kubernetes Cluster Federation"},{"location":"kubernetes/edx.html#custom-resources","text":"A resource is an API endpoint which stores a collection of API objects. Ex: Pod resource contains all Pod objects. k8s existing resources fullfill most requirements. Can create new resources using custom resources dynamic in nature appear/disappear in already running cluster @ anytime. Make resource declarative: create/install custom controller interprets resource structure performs required actions can be deployed/managed in pre-running clusters Two Methods to Add Custom Resources: Custom Resource Definitions (CRDs) Easiest doesn't require programming knowledge building custom controller would require some programming API Aggregation Fine grained control subordinate API servers sit behind primary API server & act as proxy","title":"Custom Resources"},{"location":"kubernetes/edx.html#helm","text":"k8s manifests: Deployments Services Volume Claims Ingress etc Chart Can bundle manifests after templatizing them into well-defined format, along with other metadata. can be served via repositories like rpm & deb packages. Helm: Package manager (like yum & apt ) for k8s. install/update/delete Charts in k8s cluster. Two components: Client - Helm - runs on user's workstation. Server - tiller - runs inside k8s cluster. Client helm connects to server tiller to manage Charts. Github Helm Charts","title":"Helm"},{"location":"kubernetes/edx.html#monitoring-and-logging","text":"Collect resource usage data by Pods, Services, nodes, etc to determine scaling decisions. Heapster cluster-wide aggregator of monitoring & event data native k8s support Prometheus part of CNCF can be used to gather resource usage from k8s components and objects. Using client libraries - can instrument code of app. Logging important for debugging - collected from objects, nodes, etc. Elasticsearch Uses fluentd w/custom config as an agent on nodes. open source data collector. part for CNCF.","title":"Monitoring and Logging"},{"location":"kubernetes/edx.html#ch16-community","text":"Understand the importance of Kubernetes community. Learn about the different channels to interact with the Kubernetes community. List major CNCF events. K8sPort - recognizes / rewards community members Weekly Meetings using video conference tools. https://groups.google.com/forum/#!forum/kubernetes-community-video-chat Meetup Groups https://www.meetup.com/topics/kubernetes/ Slack Channels: #kubernetes-users Mailing Lists Users Developers Special Interest Groups Scheduling, authorization, networking, documentation, etc Existing SIGs New SIG Creation Stack Overflow CNCF Events Three of the major conferences it organizes are: KubeCon + CloudNativeCon Europe KubeCon + CloudNativeCon North America KubeCon + CloudNativeCon China. Next Course: - Kubernetes Fundamentals - Kubernetes Administrator - Certified Kubernetes Adminsitrator Exam - Certified Kubernetes Application Developer Program","title":"Ch.16 Community"},{"location":"networking/arp.html","text":"Address Resolution Protocol (ARP) \u00b6 https://www.youtube.com/watch?v=NpiORFxyM4c ARP is a protocol for mapping an IP address to a physical MAC address on a local area network. Program used by one device to find another device's MAC address based on that device's IP Device's maintain ARP Cache tables mapping IP to MAC arp -a lists table How does ARP work? Client ( 192.168.1.10 ) wants to communicate with Server ( 192.168.1.50 ) Client knows Server has IP of 192.168.1.50 and is local. Client broadcasts packet to all IPs: \"Are you 192.168.1.50 ? Please send MAC\" IP Source: 192.168.1.10 MAC Source: oe:cd:ef:12:34:56 IP Dest: 192.168.1.50 MAC Dest: ff:ff:ff:ff:ff:ff (broadcast) For each device that 'hears' broadcast: if not 192.168.1.50 silently ignore packet Server 'hears' packet - sends Unicast (1-to-1 communication) to Client IP Source: 192.168.1.50 MAC Source: fa:ed:db:91:11:19 IP Dest: 192.168.1.10 Mac Dest: oe:cd:ef:12:34:56 (unicast) Client confirms by send Server a request IP Source: 192.168.1.10 MAC Source: oe:cd:ef:12:34:56 IP Dest: 192.168.1.50 MAC Source: fa:ed:db:91:11:19 (unicast) Client updates ARP Cache table for future reference ARP Summary \u00b6 Layer 2 protocol (aruably as Layer 2.5 as it exists between layers) Uses Layer 3 IP address to find Layer 2 MAC address Operates on LAN (same broadcast domain) Relies on broadcasting Uses/Updates ARP Table","title":"ARP"},{"location":"networking/arp.html#address-resolution-protocol-arp","text":"https://www.youtube.com/watch?v=NpiORFxyM4c ARP is a protocol for mapping an IP address to a physical MAC address on a local area network. Program used by one device to find another device's MAC address based on that device's IP Device's maintain ARP Cache tables mapping IP to MAC arp -a lists table How does ARP work? Client ( 192.168.1.10 ) wants to communicate with Server ( 192.168.1.50 ) Client knows Server has IP of 192.168.1.50 and is local. Client broadcasts packet to all IPs: \"Are you 192.168.1.50 ? Please send MAC\" IP Source: 192.168.1.10 MAC Source: oe:cd:ef:12:34:56 IP Dest: 192.168.1.50 MAC Dest: ff:ff:ff:ff:ff:ff (broadcast) For each device that 'hears' broadcast: if not 192.168.1.50 silently ignore packet Server 'hears' packet - sends Unicast (1-to-1 communication) to Client IP Source: 192.168.1.50 MAC Source: fa:ed:db:91:11:19 IP Dest: 192.168.1.10 Mac Dest: oe:cd:ef:12:34:56 (unicast) Client confirms by send Server a request IP Source: 192.168.1.10 MAC Source: oe:cd:ef:12:34:56 IP Dest: 192.168.1.50 MAC Source: fa:ed:db:91:11:19 (unicast) Client updates ARP Cache table for future reference","title":"Address Resolution Protocol (ARP)"},{"location":"networking/arp.html#arp-summary","text":"Layer 2 protocol (aruably as Layer 2.5 as it exists between layers) Uses Layer 3 IP address to find Layer 2 MAC address Operates on LAN (same broadcast domain) Relies on broadcasting Uses/Updates ARP Table","title":"ARP Summary"},{"location":"networking/osi.html","text":"OSI Model \u00b6 https://www.youtube.com/watch?v=nFnLPGk8WjA Layers \u00b6 Layer Name Mnemonic Mnemonic Mnemonic 7 Application A ll A ll A way 6 Presentation P eople P eople P izza 5 Session S eem S hould S ausage 4 Transport T o T ry T hrow 3 Network N eed N ew N ot 2 Data Link D omino D r. D o 1 Physical P izza P epper P lease Physical Path \u00b6 Sending device starts with Application (Layer 7) Data moves down Layers from 7 => 1 Data moves along Network medium Data moves up Layers from 1 => 7 to receiving device Logical Path \u00b6 Layer Sender Receiver Application Generates Data Receives Data Presentation Encrpyts/Compresses Decrypts/Decompresses Session Transport Chops into Segments Puts segments together Network Makes Packets Opens Packets Data Link Makes Frames Opens Frames Physical Layer Notes \u00b6 Application (Layer 7) \u00b6 non-technical About user's application Chrome/Firefox/Outlook/etc technically refers to application protocols HTTP, SMTP, POP3, IMAP4, etc facilitate communications between application and operating system Application data generated here Presentation (Layer 6) \u00b6 Provides variety of coding/conversion functions on application data Ensures information sent from app layer of client is understood by app layer of server trys to translate app data into certain format that every system can understand Session (Layer 5) \u00b6 Establish, manage, terminate connectiosn between sender and receiver Transport (Layer 4) \u00b6 Accepts data from Session Chops data into smaller segments Adds Header information Destination Port Number Source Port Number Sequence Number used by receiver to put segments back in order Main Protocols: TCP (dominant protocol) UDP Network (Layer 3) \u00b6 Primary Protocol: IP Takes segments and adds actual header information Senders IP address Receivers IP address Packets are created All about IP address and routing Data Link (Layer 2) \u00b6 More Header information added Adds Frame Header Source MAC Address Desination MAC Address Adds Trailing FCS Exists @ NIC Physical (Layer 1) \u00b6 Accepts Frames from Data Link layers Generates Bits Bits made of electrical pulses or light depends on medium (copper vs fiber etc)","title":"OSI"},{"location":"networking/osi.html#osi-model","text":"https://www.youtube.com/watch?v=nFnLPGk8WjA","title":"OSI Model"},{"location":"networking/osi.html#layers","text":"Layer Name Mnemonic Mnemonic Mnemonic 7 Application A ll A ll A way 6 Presentation P eople P eople P izza 5 Session S eem S hould S ausage 4 Transport T o T ry T hrow 3 Network N eed N ew N ot 2 Data Link D omino D r. D o 1 Physical P izza P epper P lease","title":"Layers"},{"location":"networking/osi.html#physical-path","text":"Sending device starts with Application (Layer 7) Data moves down Layers from 7 => 1 Data moves along Network medium Data moves up Layers from 1 => 7 to receiving device","title":"Physical Path"},{"location":"networking/osi.html#logical-path","text":"Layer Sender Receiver Application Generates Data Receives Data Presentation Encrpyts/Compresses Decrypts/Decompresses Session Transport Chops into Segments Puts segments together Network Makes Packets Opens Packets Data Link Makes Frames Opens Frames Physical","title":"Logical Path"},{"location":"networking/osi.html#layer-notes","text":"","title":"Layer Notes"},{"location":"networking/osi.html#application-layer-7","text":"non-technical About user's application Chrome/Firefox/Outlook/etc technically refers to application protocols HTTP, SMTP, POP3, IMAP4, etc facilitate communications between application and operating system Application data generated here","title":"Application (Layer 7)"},{"location":"networking/osi.html#presentation-layer-6","text":"Provides variety of coding/conversion functions on application data Ensures information sent from app layer of client is understood by app layer of server trys to translate app data into certain format that every system can understand","title":"Presentation (Layer 6)"},{"location":"networking/osi.html#session-layer-5","text":"Establish, manage, terminate connectiosn between sender and receiver","title":"Session (Layer 5)"},{"location":"networking/osi.html#transport-layer-4","text":"Accepts data from Session Chops data into smaller segments Adds Header information Destination Port Number Source Port Number Sequence Number used by receiver to put segments back in order Main Protocols: TCP (dominant protocol) UDP","title":"Transport (Layer 4)"},{"location":"networking/osi.html#network-layer-3","text":"Primary Protocol: IP Takes segments and adds actual header information Senders IP address Receivers IP address Packets are created All about IP address and routing","title":"Network (Layer 3)"},{"location":"networking/osi.html#data-link-layer-2","text":"More Header information added Adds Frame Header Source MAC Address Desination MAC Address Adds Trailing FCS Exists @ NIC","title":"Data Link (Layer 2)"},{"location":"networking/osi.html#physical-layer-1","text":"Accepts Frames from Data Link layers Generates Bits Bits made of electrical pulses or light depends on medium (copper vs fiber etc)","title":"Physical (Layer 1)"},{"location":"networking/subnetting.html","text":"Subnetting \u00b6 IPv4 Classes \u00b6 Notes on https://www.youtube.com/watch?v=vcArZIAmnYQ&list=PLSNNzog5eydt_plAtt3k_LYuIXrAS4aDZ Class First Octet decimal (range) First Octet binary (range) IP Range Subnet Mask Hosts per Network ID # of Networks Class A 0-127 0XXXXXXX 0.0.0.0 - 127.255.255.255 255.0.0.0 2 24 -2 2 7 Class B 128-191 10XXXXXX 128.0.0.0 - 191.255.255.255 255.255.0.0 2 16 -2 2 14 Class C 192-223 110XXXXX 192.0.0.0 - 223.255.255.255 255.255.255.0 2 8 -2 2 21 Class D (Multicast) 224-239 1110XXXX 224.0.0.0 - 239.255.255.255 Class E (Experimental) 240-255 1111XXXX 240.0.0.0 - 255.255.255.255 h = 2 x -2 n = 2 y h = 2 x -2 ; x is the number of 0's (in binary) in the subnet mask n = 2 y ; y is the number of 1's (in binary) in the subnet mask - only including unfixed values. The fixed values in the First Octet (in binary) are not counted towards y Subnet Masks \u00b6 https://www.youtube.com/watch?v=yLeuGOOrUvo&list=PLSNNzog5eydt_plAtt3k_LYuIXrAS4aDZ&index=4 Why do we need them? Indicates which devices are local vs remote. How? Compare Device IPs (in binary) where Subnet Mask (in binary) == 1 Subnet Mask indicates which binary values from each device's IP should be used to decide if devices are local/remote. Example \u00b6 Device A Subnet Mask: 255.255.255.0 Device A IP Address: 10.1.151.2 Device B IP Address: 10.1.151.3 Device C IP Address: 64.227.160.23 Convert Subnet Masks and IPs into Binary Label 1 st Octet 2 nd Octet 3 rd Octet 4 th Octet A 's Subnet Mask 11111111 11111111 11111111 00000000 A 's IP Address: 00001010 00000001 10010111 00000010 B 's IP Address: 00001010 00000001 10010111 00000011 Compare A to B Matches Matches Matches N/A - Subnet Mask is 0 C 's IP Address: 01000000 11100011 10100000 00010111 Compare A to C Doesn't Match Doesn't Match Doesn't Match Device A and B are on same network. Device A and C are on different networks. Remote vs Local Protocol \u00b6 Device A wants to communicate with Device B (local) A uses ARP to ask for B 's MAC Address via B 's IP ARP: https://www.youtube.com/watch?v=NpiORFxyM4c B replies with B 's MAC Address A uses B 's MAC to make Frames and communicate with B All communication between A & B via Switch (layer 2 Device) Device A wants to communicate with Device C (remote network) A uses ARP to ask for Default Gateway's MAC Address based on Default Gateway's IP address. Default Gateway replies to A with Default Gateway's MAC Address A sends packets (for C ) to Default Gateway's MAC Address, which delivers A 's packets to remote computer C ARP used in both Remote and Local communications IP Address used for remote communications MAC Address used for local communications Switch (layer 2 device) used for Local communications Default Gateway (layer 3 device) used for Remote communications Subnet Shorthand \u00b6 Shorthand is the count of 1 's in the binary form of the subnet mask. Shorthand Binary Decimal /8 11111111.00000000.00000000.00000000 255.0.0.0 /16 11111111.11111111.00000000.00000000 255.255.0.0 /5 11111000.00000000.00000000.00000000 248.0.0.0 /20 11111111.11111111.11110000.0000 255.255.240.0 /25 11111111.11111111.11111111.10000000 255.255.255.128 Subnetting Table \u00b6 Subnet 1 2 4 8 16 32 64 Host 256 128 64 32 16 8 4 Subnet Mask /24 /25 /26 /27 /28 /29 /30 Example Problems \u00b6 Example 1 \u00b6 IP Address Given: 192.168.1.0 Hosts Needed: 60 Subnets Needed: 4 ___ SUBS: 2 | 4 | 8 | 16 | 32 | 64 | 128 | 256 192 .168.1.X: 128 | 64 | 32 | 16 | 8 | 4 | 2 | 1 HOST: 256 | 128 | 64 | 32 | 16 | 8 | 4 | 2 ^^ CLASS: C { HOST IPS } DEFAULT SNM: /24 192 .168.1 { .0 +1 = > | .1 <-> .62 | < = -1 .63 } CUSTOM SNM: /26 { .64 +1 = > | .65 <-> .126 | < = -1 .127 } BROAD HOSTS ( #-2): 62 NET { .128 +1 => | .129 <-> .190 | <= -1 .191 } CAST SUBNETS: 4 { .192 +1 = > | .192 <-> .254 | < = -1 .255 } { .256 ^^^ Invalid","title":"Subnetting"},{"location":"networking/subnetting.html#subnetting","text":"","title":"Subnetting"},{"location":"networking/subnetting.html#ipv4-classes","text":"Notes on https://www.youtube.com/watch?v=vcArZIAmnYQ&list=PLSNNzog5eydt_plAtt3k_LYuIXrAS4aDZ Class First Octet decimal (range) First Octet binary (range) IP Range Subnet Mask Hosts per Network ID # of Networks Class A 0-127 0XXXXXXX 0.0.0.0 - 127.255.255.255 255.0.0.0 2 24 -2 2 7 Class B 128-191 10XXXXXX 128.0.0.0 - 191.255.255.255 255.255.0.0 2 16 -2 2 14 Class C 192-223 110XXXXX 192.0.0.0 - 223.255.255.255 255.255.255.0 2 8 -2 2 21 Class D (Multicast) 224-239 1110XXXX 224.0.0.0 - 239.255.255.255 Class E (Experimental) 240-255 1111XXXX 240.0.0.0 - 255.255.255.255 h = 2 x -2 n = 2 y h = 2 x -2 ; x is the number of 0's (in binary) in the subnet mask n = 2 y ; y is the number of 1's (in binary) in the subnet mask - only including unfixed values. The fixed values in the First Octet (in binary) are not counted towards y","title":"IPv4 Classes"},{"location":"networking/subnetting.html#subnet-masks","text":"https://www.youtube.com/watch?v=yLeuGOOrUvo&list=PLSNNzog5eydt_plAtt3k_LYuIXrAS4aDZ&index=4 Why do we need them? Indicates which devices are local vs remote. How? Compare Device IPs (in binary) where Subnet Mask (in binary) == 1 Subnet Mask indicates which binary values from each device's IP should be used to decide if devices are local/remote.","title":"Subnet Masks"},{"location":"networking/subnetting.html#example","text":"Device A Subnet Mask: 255.255.255.0 Device A IP Address: 10.1.151.2 Device B IP Address: 10.1.151.3 Device C IP Address: 64.227.160.23 Convert Subnet Masks and IPs into Binary Label 1 st Octet 2 nd Octet 3 rd Octet 4 th Octet A 's Subnet Mask 11111111 11111111 11111111 00000000 A 's IP Address: 00001010 00000001 10010111 00000010 B 's IP Address: 00001010 00000001 10010111 00000011 Compare A to B Matches Matches Matches N/A - Subnet Mask is 0 C 's IP Address: 01000000 11100011 10100000 00010111 Compare A to C Doesn't Match Doesn't Match Doesn't Match Device A and B are on same network. Device A and C are on different networks.","title":"Example"},{"location":"networking/subnetting.html#remote-vs-local-protocol","text":"Device A wants to communicate with Device B (local) A uses ARP to ask for B 's MAC Address via B 's IP ARP: https://www.youtube.com/watch?v=NpiORFxyM4c B replies with B 's MAC Address A uses B 's MAC to make Frames and communicate with B All communication between A & B via Switch (layer 2 Device) Device A wants to communicate with Device C (remote network) A uses ARP to ask for Default Gateway's MAC Address based on Default Gateway's IP address. Default Gateway replies to A with Default Gateway's MAC Address A sends packets (for C ) to Default Gateway's MAC Address, which delivers A 's packets to remote computer C ARP used in both Remote and Local communications IP Address used for remote communications MAC Address used for local communications Switch (layer 2 device) used for Local communications Default Gateway (layer 3 device) used for Remote communications","title":"Remote vs Local Protocol"},{"location":"networking/subnetting.html#subnet-shorthand","text":"Shorthand is the count of 1 's in the binary form of the subnet mask. Shorthand Binary Decimal /8 11111111.00000000.00000000.00000000 255.0.0.0 /16 11111111.11111111.00000000.00000000 255.255.0.0 /5 11111000.00000000.00000000.00000000 248.0.0.0 /20 11111111.11111111.11110000.0000 255.255.240.0 /25 11111111.11111111.11111111.10000000 255.255.255.128","title":"Subnet Shorthand"},{"location":"networking/subnetting.html#subnetting-table","text":"Subnet 1 2 4 8 16 32 64 Host 256 128 64 32 16 8 4 Subnet Mask /24 /25 /26 /27 /28 /29 /30","title":"Subnetting Table"},{"location":"networking/subnetting.html#example-problems","text":"","title":"Example Problems"},{"location":"networking/subnetting.html#example-1","text":"IP Address Given: 192.168.1.0 Hosts Needed: 60 Subnets Needed: 4 ___ SUBS: 2 | 4 | 8 | 16 | 32 | 64 | 128 | 256 192 .168.1.X: 128 | 64 | 32 | 16 | 8 | 4 | 2 | 1 HOST: 256 | 128 | 64 | 32 | 16 | 8 | 4 | 2 ^^ CLASS: C { HOST IPS } DEFAULT SNM: /24 192 .168.1 { .0 +1 = > | .1 <-> .62 | < = -1 .63 } CUSTOM SNM: /26 { .64 +1 = > | .65 <-> .126 | < = -1 .127 } BROAD HOSTS ( #-2): 62 NET { .128 +1 => | .129 <-> .190 | <= -1 .191 } CAST SUBNETS: 4 { .192 +1 = > | .192 <-> .254 | < = -1 .255 } { .256 ^^^ Invalid","title":"Example 1"},{"location":"pandas/pandas.html","text":"Pandas Notes \u00b6 Data Structures \u00b6 Indexes: Sequence of labels Immutable (Like dictionary keys Homogenous in data type (Like NumPy array) Series: 1D array with Index DataFrames: 2D array with Series as columns Index \u00b6 Index Examples \u00b6 import pandas as pd prices = [ 10.70 , 10.86 , 10.74 , 10.71 , 10.79 ] shares = pd . Series ( prices ) days = [ 'Mon' , 'Tue' , 'Wed' , 'Thur' , 'Fri' ] pd . Series ( prices , index = days ) shares . index . name = 'weekday' # Indivdual elements in index are immutable shares . index [ 2 ] = 'Wednesday' #error # entire index can be re-built shares . index = [ 'Monday' , 'Tuesday' , 'Wednesday' , 'Thursday' , 'Friday' ] Index Multiple Values \u00b6 Indexes can be built with multiple values using tuples df = df . set_index ([ 'col1' , 'col2' ]) print ( df . index . name ) => None print ( df . index . names ) => [ 'col1' , 'col2' ] df.unstack(level='col1') \u00b6 df.unstack a multilevel index results in the same type of hierarchical columns from df.pivot df.stack(level='col1') \u00b6 df.stack hierarchical columns to create multilevel index df.swaplevel() \u00b6 swaps inner/outter indexes in multilevel index df.sort_index() \u00b6 pd.melt() \u00b6 pd . melt ( df , id_vars = [ 'colN' ], value_vars = [ 'colN' ]) pd . melt ( df , id_vars = [ 'colN' ], var_name = 'col1' , value_name = 'col2' ) Index Sorting \u00b6 df = df . sort_index () df.loc[] \u00b6 stocks . loc [( 'CSCO' , '2016-10-04' )] # returns all columns stocks . loc [( 'CSCO' , '2016-10-04' ), 'col1' ] # returns col1 stocks . loc [ 'CSCO' ] # returns rows within 'CSCO' index stocks . loc [ 'CSCO' : 'MSFT' ] # returns rows with index b/t stocks . loc [([ 'AAPL' , 'MSFT' ], '2016-10-05' ]), :] stocks . loc [([ 'AAPL' , 'MSFT' ], '2016-10-05' ), 'Close' ] stocks . loc [( 'CSCO' , [ '2016-10-05' , '2016-10-03' ]), :] Slicing (both indexes) \u00b6 stocks . loc [( slice ( None ), slice ( '2016-10-03' , '2016-10-04' )), :] # Look up data for CA and TX in month 2: CA_TX_month2 CA_TX_month2 = sales . loc [([ 'CA' , 'TX' ], 2 ), :] # Look up data for all states in month 2: all_month2 all_month2 = sales . loc [( slice ( None ), 2 ), :] TODO(Wes) - go back to lecture on this df.iloc[] \u00b6 TODO(Wes) List Comprehensions \u00b6 TODO(Wes) Rotating / Pivot Data \u00b6 df.pivot() \u00b6 df . pivot ( index = 'col1' , columns = 'col2' , values = 'col3' ) # all columns used as values df . pivot ( index = 'col1' , columns = 'col2' )","title":"Pandas"},{"location":"pandas/pandas.html#pandas-notes","text":"","title":"Pandas Notes"},{"location":"pandas/pandas.html#data-structures","text":"Indexes: Sequence of labels Immutable (Like dictionary keys Homogenous in data type (Like NumPy array) Series: 1D array with Index DataFrames: 2D array with Series as columns","title":"Data Structures"},{"location":"pandas/pandas.html#index","text":"","title":"Index"},{"location":"pandas/pandas.html#index-examples","text":"import pandas as pd prices = [ 10.70 , 10.86 , 10.74 , 10.71 , 10.79 ] shares = pd . Series ( prices ) days = [ 'Mon' , 'Tue' , 'Wed' , 'Thur' , 'Fri' ] pd . Series ( prices , index = days ) shares . index . name = 'weekday' # Indivdual elements in index are immutable shares . index [ 2 ] = 'Wednesday' #error # entire index can be re-built shares . index = [ 'Monday' , 'Tuesday' , 'Wednesday' , 'Thursday' , 'Friday' ]","title":"Index Examples"},{"location":"pandas/pandas.html#index-multiple-values","text":"Indexes can be built with multiple values using tuples df = df . set_index ([ 'col1' , 'col2' ]) print ( df . index . name ) => None print ( df . index . names ) => [ 'col1' , 'col2' ]","title":"Index Multiple Values"},{"location":"pandas/pandas.html#dfunstacklevelcol1","text":"df.unstack a multilevel index results in the same type of hierarchical columns from df.pivot","title":"df.unstack(level='col1')"},{"location":"pandas/pandas.html#dfstacklevelcol1","text":"df.stack hierarchical columns to create multilevel index","title":"df.stack(level='col1')"},{"location":"pandas/pandas.html#dfswaplevel","text":"swaps inner/outter indexes in multilevel index","title":"df.swaplevel()"},{"location":"pandas/pandas.html#dfsort_index","text":"","title":"df.sort_index()"},{"location":"pandas/pandas.html#pdmelt","text":"pd . melt ( df , id_vars = [ 'colN' ], value_vars = [ 'colN' ]) pd . melt ( df , id_vars = [ 'colN' ], var_name = 'col1' , value_name = 'col2' )","title":"pd.melt()"},{"location":"pandas/pandas.html#index-sorting","text":"df = df . sort_index ()","title":"Index Sorting"},{"location":"pandas/pandas.html#dfloc","text":"stocks . loc [( 'CSCO' , '2016-10-04' )] # returns all columns stocks . loc [( 'CSCO' , '2016-10-04' ), 'col1' ] # returns col1 stocks . loc [ 'CSCO' ] # returns rows within 'CSCO' index stocks . loc [ 'CSCO' : 'MSFT' ] # returns rows with index b/t stocks . loc [([ 'AAPL' , 'MSFT' ], '2016-10-05' ]), :] stocks . loc [([ 'AAPL' , 'MSFT' ], '2016-10-05' ), 'Close' ] stocks . loc [( 'CSCO' , [ '2016-10-05' , '2016-10-03' ]), :]","title":"df.loc[]"},{"location":"pandas/pandas.html#slicing-both-indexes","text":"stocks . loc [( slice ( None ), slice ( '2016-10-03' , '2016-10-04' )), :] # Look up data for CA and TX in month 2: CA_TX_month2 CA_TX_month2 = sales . loc [([ 'CA' , 'TX' ], 2 ), :] # Look up data for all states in month 2: all_month2 all_month2 = sales . loc [( slice ( None ), 2 ), :] TODO(Wes) - go back to lecture on this","title":"Slicing (both indexes)"},{"location":"pandas/pandas.html#dfiloc","text":"TODO(Wes)","title":"df.iloc[]"},{"location":"pandas/pandas.html#list-comprehensions","text":"TODO(Wes)","title":"List Comprehensions"},{"location":"pandas/pandas.html#rotating-pivot-data","text":"","title":"Rotating / Pivot Data"},{"location":"pandas/pandas.html#dfpivot","text":"df . pivot ( index = 'col1' , columns = 'col2' , values = 'col3' ) # all columns used as values df . pivot ( index = 'col1' , columns = 'col2' )","title":"df.pivot()"},{"location":"python/10apps.html","text":"Learn Python by Building 10 Apps \u00b6 Accept user input \u00b6 user_input = input ( \"Prompt: \" ) if / else statements \u00b6 if condition and condition or condition : do some things elif conidtion or condition : do some things else : do some things while loops \u00b6 while True : do some things string formatting \u00b6 name = 'Wes' print ( \"Hello {} \" . format ( name )) print ( f \"Hello { name } \" ) print ( f 'Hello { name } ' ) functions \u00b6 def my_function (): do some things return new_thing App3 - birthday \u00b6 dates \u00b6 import datetime today = datetime . date . today () # date = datetime.date(year, month, day) May_1_2018 = datetime . date ( 2018 , 5 , 1 ) days_difference = today . day - May_1_2018 . day times \u00b6 timespans \u00b6 App4 \u00b6 multiple files / modules \u00b6 file i/o \u00b6 import os filename = os . path . abspath ( os . path . join ( '.' , 'journals' , name + '.jrl' )) if os . path . exists ( filename ): with open ( filename ) as fin : for entry in fin . readlines (): do some things with open ( filename , 'w' ) as fout : for entry in journal_data : fout . write ( entry + ' \\n ' ) os independent path management \u00b6 filename = os . path . abspath ( os . path . join ( '.' , 'journals' , name + '.jrl' )) for-in loops \u00b6 for n in item : print ( n ) iterators \u00b6 _ _name_ _ \u00b6 if __name__ == '__main__' : main () doc strings \u00b6 def load ( name ): \"\"\" This method creates and loads a new journal. :param name: The base name of the journal to load. :return: A new journal data structure populated with the file data. \"\"\" App5 \u00b6 screen scraping \u00b6 import requests import bs4 url = 'https://www.wunderground.com/weather-forecast/72202' # get page response = requests . get ( url ) # parse html (reponse.text) into DOM soup = bs4 . BeautifulSoup ( response . text , 'html.parser' ) # get location, condition, temp, scale (F vs C) loc = soup . find ( class_ = 'region-content-header' ) . find ( 'h1' ) . get_text () condition = soup . find ( class_ = 'condition-icon' ) . get_text () temp = soup . find ( class_ = 'wu-unit-temperature' ) . find ( class_ = 'wu-value' ) . get_text () scale = soup . find ( class_ = 'wu-unit-temperature' ) . find ( class_ = 'wu-label' ) . get_text () http requests \u00b6 import requests url = 'https://www.wunderground.com/weather-forecast/72202' response = requests . get ( url ) virtual environments \u00b6 tuples and named tuples \u00b6 m = ( 22.5 , 44.234 , 19.02 , 'strong' ) temp = m [ 0 ] quality = m [ 3 ] m = 22.5 , 44.234 , 19.02 , 'strong' print ( m ) # (22.5, 44.234, 19.02, 'strong') t , la , lo , q = m # t=22.5, la=44.234, lo=19.02, q='strong' import collections WeatherReport = collections . namedtuple ( 'Measurement' , 'temp, lat, long, quality' ) m = Measurement ( 22.5 , 44.234 , 19.02 , 'strong' ) temp = m [ 0 ] temp = m . temp quality = m . quality print ( m ) # Measurement(temp=22.5, lat=44.234, long=19.02, quality='strong') beautiful soup package \u00b6 import bs4 soup = bs4 . BeautifulSoup ( reponse . text , 'html.parser' ) slicing \u00b6 nums = [ 2 , 3 , 5 , 6 , 11 , 13 , 17 , 19 , 23 ] first_prime = nums [ 0 ] # 2 last_prime = nums [ - 1 ] # 23 lowest_four = nums [ 0 : 4 ] # [2, 3, 5, 7] lowest_four = nums [: 4 ] # [2, 3, 5, 7] Middle = nums [ 3 : 6 ] # [7, 11, 13] last_four = nums [ 5 : 9 ] # [13, 17, 19, 23] last_four = nums [ 5 :] # [13, 17, 19, 23] last_four = nums [ - 4 :] # [13, 17, 19, 23] App6 \u00b6 http clients (binary data) \u00b6 import os import shutil import requests def get_cat ( folder , name ): url = 'http://consuming-python-services-api.azurewebsites.net/cats/random' data = get_data_from_url ( url ) save_image ( folder , name , data ) def get_data_from_url ( url ): response = requests . get ( url , stream = True ) return response . raw def save_image ( folder , name , data ): file_name = os . path . join ( folder , name + '.jpg' ) with open ( file_name , 'wb' ) as fout : shutil . copyfileobj ( data , fout ) subprocesses / platform \u00b6 import platform if platform . system () == 'Darwin' : subprocess . call ([ 'open' , folder ]) elif platform . system () == 'Windows' : subprocess . call ([ 'explorer' , folder ]) elif platform . system () == 'Linux' : subprocess . call ([ 'xdg-open' , folder ]) else : print ( \"We don't support your os: \" + platform . system ()) App 7 \u00b6 classes \u00b6 class Creature : # initializer def __init__ ( self , name , level ): self . name = name self . level = level def __repr__ ( self ): return \"Creature {} of level {} \" . format ( self . name , self . level ) def walk ( self ): print ( ' {} walks around' . format ( self . name )) inheritance \u00b6 class Dragon ( Creature ): def __init__ ( self , name , level , scale_thickness ): super () . __init__ ( name , level ) # initializer for Creature self . scale_thickness = scale_thickness def breath_fire (): ... duck typing and polymorphism \u00b6 # all types derive from Creature creatures = [ SmallAnimal ( 'Toad' , 1 ), Creature ( 'Tiger' , 12 ), SmallAnimal ( 'Bat' , 3 ), Dragon ( 'Dragon' , 50 , 75 ), Wizard ( 'Evil Wizard' , 1000 ) ] wiard = Wizard ( 'Gandolf' , 22 ) for c in creatures : wizard . attack ( c ) # Wizard knows how to battle any type of Creature # Duck Typing # \"If it looks/acts like a Duck -- it's a duck\" # wizard.attack(c) in most languages would require 'c' # to have inherited from Creature, given that .attack() # takes a creature. Python's Duck Typing takes # 'things that look like creatures' App8 \u00b6 generator methods \u00b6 # yield makes fibonacci a generator method def fibonacci ( limit ): current = 0 next = 1 # after item is returned and processed, # execution returns and resumes while current < limit : current , next = next , next + current yield current # yield keyword returns one element of a sequence yield from \u00b6 def search_folders ( folder , text ): # for macOS if .DS_Store error # glob.glob(os.path.join(folder, '*')) items = os . listdir ( folder ) for item in items : full_item = os . path . join ( folder , item ) if os . path . isdir ( full_item ): yield from search_folders ( full_item , text ) else : yield from search_file ( full_item , text ) def search_file ( filename , search_text ): # matches = [] with open ( filename , 'r' , encoding = 'utf-8' ) as fin : line_num = 0 for line in fin : line_num += 1 if line . lower () . find ( search_text ) >= 0 : m = SearchResult ( line = line_num , file = filename , text = line ) yield m recursion \u00b6 def factorial ( n ): # base case - break out of loop if n <= 1 : return 1 return n * factorial ( n - 1 ) App9 \u00b6 dictionaries \u00b6 info = dict () info [ 'age' ] = 42 info [ 'loc' ] = 'Italy' info = dict ( age = 42 , loc = 'Italy' ) info = { 'age' : 42 , 'loc' : 'Italy' } location = info [ 'loc' ] if 'age' in info : # test for key # use info['age'] lambda methods \u00b6 def find_sig_nums ( nums , predicate ): for n in nums : if predicate ( n ): yield n number = [ 1 , 1 , 2 , 3 , 5 , 8 , 21 , 34 ] sig = find_sig_nums ( numbers , lambda x : x % 2 == 1 ) # sig -> [1, 1, 3, 5, 13, 21] csv file format and parsing \u00b6 class Purchase : def __init__ ( self , street , city , zipcode , state , beds , baths , sq__ft , home_type , sale_date , price , latitude , longitude ): self . longitude = longitude self . latitude = latitude self . price = price self . sale_date = sale_date self . type = home_type self . sq__ft = sq__ft self . baths = baths self . beds = beds self . state = state self . zip = zipcode self . city = city self . street = street @staticmethod def create_from_dict ( lookup ): return Purchase ( lookup [ 'street' ], lookup [ 'city' ], lookup [ 'zip' ], lookup [ 'state' ], int ( lookup [ 'beds' ]), int ( lookup [ 'baths' ]), int ( lookup [ 'sq__ft' ]), lookup [ 'type' ], lookup [ 'sale_date' ], float ( lookup [ 'price' ]), float ( lookup [ 'latitude' ]), float ( lookup [ 'longitude' ]) ) def load_file ( filename ): with open ( filename , 'r' , encoding = 'utf-8' ) as fin : reader = csv . DictReader ( fin ) purchases = [] for row in reader : p = Purchase . create_from_dict ( row ) purchases . append ( p ) return purchases coding for python 3 and 2 \u00b6 try : import statistics # only Python 3.4.3+ except : import statistics_2_stand_in as statistics numbers = [ 1 , 6 , 99 , ... , 5 ] the_avg = statistics . mean ( numbers ) # statistics_2_stand_in.py def mean ( lst ): # your implementation of mean here... return avg list comprehensions \u00b6 paying_usernames = [ u . name # projection for u in get_active_customers () # source if u . last_purchase == today # filter ] generator expressions \u00b6 # works like generator methods / yield paying_usernames = ( u . name for u in get_active_customers () if u . last_purchase == today ) # You can not index into generators data pipelines \u00b6 all_transactions = get_tx_stream () interesting_tx = ( tx for tx in all_transactions # calls transaction stream if is_interesting ( tx ) ) potentially_sellable_tx = ( tx for tx in interesting_tx # calls above if is_sellable ( tx ) ) nearby_sellable_interesting_tx = ( tx for tx in potentially_sellable_tx # calls above if is_nearby ( tx ) ) App10 \u00b6 error and exception handling \u00b6 if not search_text or not search_text . strip (): raise ValueError ( \"Search text is required.\" ) try / except \u00b6 try : method1 () method2 () method3 () except ConnectionError as ce : # handle network error except Exception as x : # handle general error handling errors by type \u00b6 try : search = input ( \"Movie search text (x to exit): \" ) if search != 'x' : results = movie_svc . find_movies ( search ) print ( \"Found {} results.\" . format ( len ( results ))) for r in results : print ( \" {} -- {} \" . format ( r . year , r . title )) print () # Order from more specfic to more general except ValueError : print ( \"Error: Search text is required.\" ) except requests . exceptions . ConnectionError : print ( \"Error: Your network is down.\" ) except Exception as x : print ( \"Unexpected error. Details: {} \" . format ( x )) raising errors \u00b6 def find_movies ( search_text ): if not search_text or not search_text . strip (): raise ValueError ( \"Search text is required.\" ) # raise will immediately return from function with error","title":"10Apps"},{"location":"python/10apps.html#learn-python-by-building-10-apps","text":"","title":"Learn Python by Building 10 Apps"},{"location":"python/10apps.html#accept-user-input","text":"user_input = input ( \"Prompt: \" )","title":"Accept user input"},{"location":"python/10apps.html#if-else-statements","text":"if condition and condition or condition : do some things elif conidtion or condition : do some things else : do some things","title":"if / else statements"},{"location":"python/10apps.html#while-loops","text":"while True : do some things","title":"while loops"},{"location":"python/10apps.html#string-formatting","text":"name = 'Wes' print ( \"Hello {} \" . format ( name )) print ( f \"Hello { name } \" ) print ( f 'Hello { name } ' )","title":"string formatting"},{"location":"python/10apps.html#functions","text":"def my_function (): do some things return new_thing","title":"functions"},{"location":"python/10apps.html#app3-birthday","text":"","title":"App3 - birthday"},{"location":"python/10apps.html#dates","text":"import datetime today = datetime . date . today () # date = datetime.date(year, month, day) May_1_2018 = datetime . date ( 2018 , 5 , 1 ) days_difference = today . day - May_1_2018 . day","title":"dates"},{"location":"python/10apps.html#times","text":"","title":"times"},{"location":"python/10apps.html#timespans","text":"","title":"timespans"},{"location":"python/10apps.html#app4","text":"","title":"App4"},{"location":"python/10apps.html#multiple-files-modules","text":"","title":"multiple files / modules"},{"location":"python/10apps.html#file-io","text":"import os filename = os . path . abspath ( os . path . join ( '.' , 'journals' , name + '.jrl' )) if os . path . exists ( filename ): with open ( filename ) as fin : for entry in fin . readlines (): do some things with open ( filename , 'w' ) as fout : for entry in journal_data : fout . write ( entry + ' \\n ' )","title":"file i/o"},{"location":"python/10apps.html#os-independent-path-management","text":"filename = os . path . abspath ( os . path . join ( '.' , 'journals' , name + '.jrl' ))","title":"os independent path management"},{"location":"python/10apps.html#for-in-loops","text":"for n in item : print ( n )","title":"for-in loops"},{"location":"python/10apps.html#iterators","text":"","title":"iterators"},{"location":"python/10apps.html#_-_name_-_","text":"if __name__ == '__main__' : main ()","title":"_ _name_ _"},{"location":"python/10apps.html#doc-strings","text":"def load ( name ): \"\"\" This method creates and loads a new journal. :param name: The base name of the journal to load. :return: A new journal data structure populated with the file data. \"\"\"","title":"doc strings"},{"location":"python/10apps.html#app5","text":"","title":"App5"},{"location":"python/10apps.html#screen-scraping","text":"import requests import bs4 url = 'https://www.wunderground.com/weather-forecast/72202' # get page response = requests . get ( url ) # parse html (reponse.text) into DOM soup = bs4 . BeautifulSoup ( response . text , 'html.parser' ) # get location, condition, temp, scale (F vs C) loc = soup . find ( class_ = 'region-content-header' ) . find ( 'h1' ) . get_text () condition = soup . find ( class_ = 'condition-icon' ) . get_text () temp = soup . find ( class_ = 'wu-unit-temperature' ) . find ( class_ = 'wu-value' ) . get_text () scale = soup . find ( class_ = 'wu-unit-temperature' ) . find ( class_ = 'wu-label' ) . get_text ()","title":"screen scraping"},{"location":"python/10apps.html#http-requests","text":"import requests url = 'https://www.wunderground.com/weather-forecast/72202' response = requests . get ( url )","title":"http requests"},{"location":"python/10apps.html#virtual-environments","text":"","title":"virtual environments"},{"location":"python/10apps.html#tuples-and-named-tuples","text":"m = ( 22.5 , 44.234 , 19.02 , 'strong' ) temp = m [ 0 ] quality = m [ 3 ] m = 22.5 , 44.234 , 19.02 , 'strong' print ( m ) # (22.5, 44.234, 19.02, 'strong') t , la , lo , q = m # t=22.5, la=44.234, lo=19.02, q='strong' import collections WeatherReport = collections . namedtuple ( 'Measurement' , 'temp, lat, long, quality' ) m = Measurement ( 22.5 , 44.234 , 19.02 , 'strong' ) temp = m [ 0 ] temp = m . temp quality = m . quality print ( m ) # Measurement(temp=22.5, lat=44.234, long=19.02, quality='strong')","title":"tuples and named tuples"},{"location":"python/10apps.html#beautiful-soup-package","text":"import bs4 soup = bs4 . BeautifulSoup ( reponse . text , 'html.parser' )","title":"beautiful soup package"},{"location":"python/10apps.html#slicing","text":"nums = [ 2 , 3 , 5 , 6 , 11 , 13 , 17 , 19 , 23 ] first_prime = nums [ 0 ] # 2 last_prime = nums [ - 1 ] # 23 lowest_four = nums [ 0 : 4 ] # [2, 3, 5, 7] lowest_four = nums [: 4 ] # [2, 3, 5, 7] Middle = nums [ 3 : 6 ] # [7, 11, 13] last_four = nums [ 5 : 9 ] # [13, 17, 19, 23] last_four = nums [ 5 :] # [13, 17, 19, 23] last_four = nums [ - 4 :] # [13, 17, 19, 23]","title":"slicing"},{"location":"python/10apps.html#app6","text":"","title":"App6"},{"location":"python/10apps.html#http-clients-binary-data","text":"import os import shutil import requests def get_cat ( folder , name ): url = 'http://consuming-python-services-api.azurewebsites.net/cats/random' data = get_data_from_url ( url ) save_image ( folder , name , data ) def get_data_from_url ( url ): response = requests . get ( url , stream = True ) return response . raw def save_image ( folder , name , data ): file_name = os . path . join ( folder , name + '.jpg' ) with open ( file_name , 'wb' ) as fout : shutil . copyfileobj ( data , fout )","title":"http clients (binary data)"},{"location":"python/10apps.html#subprocesses-platform","text":"import platform if platform . system () == 'Darwin' : subprocess . call ([ 'open' , folder ]) elif platform . system () == 'Windows' : subprocess . call ([ 'explorer' , folder ]) elif platform . system () == 'Linux' : subprocess . call ([ 'xdg-open' , folder ]) else : print ( \"We don't support your os: \" + platform . system ())","title":"subprocesses / platform"},{"location":"python/10apps.html#app-7","text":"","title":"App 7"},{"location":"python/10apps.html#classes","text":"class Creature : # initializer def __init__ ( self , name , level ): self . name = name self . level = level def __repr__ ( self ): return \"Creature {} of level {} \" . format ( self . name , self . level ) def walk ( self ): print ( ' {} walks around' . format ( self . name ))","title":"classes"},{"location":"python/10apps.html#inheritance","text":"class Dragon ( Creature ): def __init__ ( self , name , level , scale_thickness ): super () . __init__ ( name , level ) # initializer for Creature self . scale_thickness = scale_thickness def breath_fire (): ...","title":"inheritance"},{"location":"python/10apps.html#duck-typing-and-polymorphism","text":"# all types derive from Creature creatures = [ SmallAnimal ( 'Toad' , 1 ), Creature ( 'Tiger' , 12 ), SmallAnimal ( 'Bat' , 3 ), Dragon ( 'Dragon' , 50 , 75 ), Wizard ( 'Evil Wizard' , 1000 ) ] wiard = Wizard ( 'Gandolf' , 22 ) for c in creatures : wizard . attack ( c ) # Wizard knows how to battle any type of Creature # Duck Typing # \"If it looks/acts like a Duck -- it's a duck\" # wizard.attack(c) in most languages would require 'c' # to have inherited from Creature, given that .attack() # takes a creature. Python's Duck Typing takes # 'things that look like creatures'","title":"duck typing and polymorphism"},{"location":"python/10apps.html#app8","text":"","title":"App8"},{"location":"python/10apps.html#generator-methods","text":"# yield makes fibonacci a generator method def fibonacci ( limit ): current = 0 next = 1 # after item is returned and processed, # execution returns and resumes while current < limit : current , next = next , next + current yield current # yield keyword returns one element of a sequence","title":"generator methods"},{"location":"python/10apps.html#yield-from","text":"def search_folders ( folder , text ): # for macOS if .DS_Store error # glob.glob(os.path.join(folder, '*')) items = os . listdir ( folder ) for item in items : full_item = os . path . join ( folder , item ) if os . path . isdir ( full_item ): yield from search_folders ( full_item , text ) else : yield from search_file ( full_item , text ) def search_file ( filename , search_text ): # matches = [] with open ( filename , 'r' , encoding = 'utf-8' ) as fin : line_num = 0 for line in fin : line_num += 1 if line . lower () . find ( search_text ) >= 0 : m = SearchResult ( line = line_num , file = filename , text = line ) yield m","title":"yield from"},{"location":"python/10apps.html#recursion","text":"def factorial ( n ): # base case - break out of loop if n <= 1 : return 1 return n * factorial ( n - 1 )","title":"recursion"},{"location":"python/10apps.html#app9","text":"","title":"App9"},{"location":"python/10apps.html#dictionaries","text":"info = dict () info [ 'age' ] = 42 info [ 'loc' ] = 'Italy' info = dict ( age = 42 , loc = 'Italy' ) info = { 'age' : 42 , 'loc' : 'Italy' } location = info [ 'loc' ] if 'age' in info : # test for key # use info['age']","title":"dictionaries"},{"location":"python/10apps.html#lambda-methods","text":"def find_sig_nums ( nums , predicate ): for n in nums : if predicate ( n ): yield n number = [ 1 , 1 , 2 , 3 , 5 , 8 , 21 , 34 ] sig = find_sig_nums ( numbers , lambda x : x % 2 == 1 ) # sig -> [1, 1, 3, 5, 13, 21]","title":"lambda methods"},{"location":"python/10apps.html#csv-file-format-and-parsing","text":"class Purchase : def __init__ ( self , street , city , zipcode , state , beds , baths , sq__ft , home_type , sale_date , price , latitude , longitude ): self . longitude = longitude self . latitude = latitude self . price = price self . sale_date = sale_date self . type = home_type self . sq__ft = sq__ft self . baths = baths self . beds = beds self . state = state self . zip = zipcode self . city = city self . street = street @staticmethod def create_from_dict ( lookup ): return Purchase ( lookup [ 'street' ], lookup [ 'city' ], lookup [ 'zip' ], lookup [ 'state' ], int ( lookup [ 'beds' ]), int ( lookup [ 'baths' ]), int ( lookup [ 'sq__ft' ]), lookup [ 'type' ], lookup [ 'sale_date' ], float ( lookup [ 'price' ]), float ( lookup [ 'latitude' ]), float ( lookup [ 'longitude' ]) ) def load_file ( filename ): with open ( filename , 'r' , encoding = 'utf-8' ) as fin : reader = csv . DictReader ( fin ) purchases = [] for row in reader : p = Purchase . create_from_dict ( row ) purchases . append ( p ) return purchases","title":"csv file format and parsing"},{"location":"python/10apps.html#coding-for-python-3-and-2","text":"try : import statistics # only Python 3.4.3+ except : import statistics_2_stand_in as statistics numbers = [ 1 , 6 , 99 , ... , 5 ] the_avg = statistics . mean ( numbers ) # statistics_2_stand_in.py def mean ( lst ): # your implementation of mean here... return avg","title":"coding for python 3 and 2"},{"location":"python/10apps.html#list-comprehensions","text":"paying_usernames = [ u . name # projection for u in get_active_customers () # source if u . last_purchase == today # filter ]","title":"list comprehensions"},{"location":"python/10apps.html#generator-expressions","text":"# works like generator methods / yield paying_usernames = ( u . name for u in get_active_customers () if u . last_purchase == today ) # You can not index into generators","title":"generator expressions"},{"location":"python/10apps.html#data-pipelines","text":"all_transactions = get_tx_stream () interesting_tx = ( tx for tx in all_transactions # calls transaction stream if is_interesting ( tx ) ) potentially_sellable_tx = ( tx for tx in interesting_tx # calls above if is_sellable ( tx ) ) nearby_sellable_interesting_tx = ( tx for tx in potentially_sellable_tx # calls above if is_nearby ( tx ) )","title":"data pipelines"},{"location":"python/10apps.html#app10","text":"","title":"App10"},{"location":"python/10apps.html#error-and-exception-handling","text":"if not search_text or not search_text . strip (): raise ValueError ( \"Search text is required.\" )","title":"error and exception handling"},{"location":"python/10apps.html#try-except","text":"try : method1 () method2 () method3 () except ConnectionError as ce : # handle network error except Exception as x : # handle general error","title":"try / except"},{"location":"python/10apps.html#handling-errors-by-type","text":"try : search = input ( \"Movie search text (x to exit): \" ) if search != 'x' : results = movie_svc . find_movies ( search ) print ( \"Found {} results.\" . format ( len ( results ))) for r in results : print ( \" {} -- {} \" . format ( r . year , r . title )) print () # Order from more specfic to more general except ValueError : print ( \"Error: Search text is required.\" ) except requests . exceptions . ConnectionError : print ( \"Error: Your network is down.\" ) except Exception as x : print ( \"Unexpected error. Details: {} \" . format ( x ))","title":"handling errors by type"},{"location":"python/10apps.html#raising-errors","text":"def find_movies ( search_text ): if not search_text or not search_text . strip (): raise ValueError ( \"Search text is required.\" ) # raise will immediately return from function with error","title":"raising errors"},{"location":"sas/sas.html","text":"Style \u00b6 Determine Runtime Environment \u00b6 %macro check ; %if %symexist (_clientapp) %then %do ; %if &_clientapp = SAS Studio %then %do ; %put Running SAS Studio; %end ; %else %if &_clientapp = 'SAS Enterprise Guide' %then %do ; %put Running SAS Enterprise Guide; %end ; %end ; %else %if %index ( &sysprocessname ,DMS) %then %do ; %put Running in Display Manager; %end ; %else %if %index ( &sysprocessname ,Program) %then %do ; %let prog= %qscan ( %superq (sysprocessname), 2 , %str ( )); %put Running in batch and the program running is &prog ; %end ; %mend check ; %check","title":"SAS"},{"location":"sas/sas.html#style","text":"","title":"Style"},{"location":"sas/sas.html#determine-runtime-environment","text":"%macro check ; %if %symexist (_clientapp) %then %do ; %if &_clientapp = SAS Studio %then %do ; %put Running SAS Studio; %end ; %else %if &_clientapp = 'SAS Enterprise Guide' %then %do ; %put Running SAS Enterprise Guide; %end ; %end ; %else %if %index ( &sysprocessname ,DMS) %then %do ; %put Running in Display Manager; %end ; %else %if %index ( &sysprocessname ,Program) %then %do ; %let prog= %qscan ( %superq (sysprocessname), 2 , %str ( )); %put Running in batch and the program running is &prog ; %end ; %mend check ; %check","title":"Determine Runtime Environment"}]}